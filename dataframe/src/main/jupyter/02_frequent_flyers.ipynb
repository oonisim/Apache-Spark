{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 02\n",
    "Find the names of the 100 most frequent flyers.\n",
    "\n",
    "## Assumptions\n",
    "1. Data is clearned and not errorneous\n",
    "2. Timezone consideration is not required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.SaveMode\n",
    "import org.apache.spark.sql.functions._\n",
    "import java.time.temporal.ChronoUnit\n",
    "import java.time.{Period, LocalDate, Instant}\n",
    "import java.sql.Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark parition control based on core availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NUM_CORES = 4\n",
       "NUM_PARTITIONS = 3\n",
       "spark = <lazy>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<lazy>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val NUM_CORES = 4\n",
    "val NUM_PARTITIONS = 3\n",
    "\n",
    "lazy val spark: SparkSession = SparkSession.builder()\n",
    "    .master(\"local\")\n",
    "    .appName(\"flight\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", NUM_CORES * NUM_PARTITIONS)\n",
    "spark.conf.set(\"spark.default.parallelism\", NUM_CORES * NUM_PARTITIONS)\n",
    "\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elapsed time profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timing = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "timed: [T](label: String, code: => T)T\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val timing = new StringBuffer\n",
    "def timed[T](label: String, code: => T): T = {\n",
    "    val start = System.currentTimeMillis()\n",
    "    val result = code\n",
    "    val stop = System.currentTimeMillis()\n",
    "    timing.append(s\"Processing $label took ${stop - start} ms.\\n\")\n",
    "    result\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE_FORMAT = yyyy-MM-dd\n",
       "FLIGHTDATA_CSV_PATH = ../resources/flightData.csv\n",
       "PASSENGER_CSV_PATH = ../resources/passengers.csv\n",
       "NUM_TOP_PASSENGER = 100\n",
       "RESULT_DIR = results/topFrequentFlyers\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<console>:46: error: missing argument list for method timed\n",
       "Unapplied methods are only converted to functions when a function type is expected.\n",
       "You can make this conversion explicit by writing `timed _` or `timed(_,_)` instead of `timed`.\n",
       "       timed\n",
       "       ^\n",
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "results/topFrequentFlyers"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val DATE_FORMAT = \"yyyy-MM-dd\"\n",
    "\n",
    "val FLIGHTDATA_CSV_PATH = \"../resources/flightData.csv\"\n",
    "val PASSENGER_CSV_PATH = \"../resources/passengers.csv\"\n",
    "\n",
    "val NUM_TOP_PASSENGER = 100\n",
    "val RESULT_DIR = \"results/topFrequentFlyers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "// To flush out error: missing argument list for method timed\n",
    "println(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent Flyers\n",
    "Top N flyers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passengerId: integer (nullable = true)\n",
      " |-- numberOfFlights: long (nullable = false)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "frequentFlyers = [passengerId: int, numberOfFlights: bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, numberOfFlights: bigint]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val frequentFlyers = spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"delimiter\", \",\")\n",
    "    .option(\"dateFormat\", DATE_FORMAT)\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(FLIGHTDATA_CSV_PATH)\n",
    "    .select(\"passengerId\", \"flightId\")\n",
    "    .groupBy(\"passengerId\")\n",
    "    .count\n",
    "    .orderBy(desc(\"count\"))\n",
    "    .withColumnRenamed(\"count\", \"numberOfFlights\")\n",
    "    //--------------------------------------------------------------------------------\n",
    "    // TOP_N flyers \n",
    "    //--------------------------------------------------------------------------------\n",
    "    .limit(NUM_TOP_PASSENGER)\n",
    "    //--------------------------------------------------------------------------------\n",
    "    // Re-sort for passengerId match\n",
    "    //--------------------------------------------------------------------------------\n",
    "    .orderBy(asc(\"passengerId\"))\n",
    "    .persist\n",
    "\n",
    "frequentFlyers.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Passenger lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passengerId: integer (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LIMIT = 100\n",
       "passengers = [passengerId: int, firstName: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, firstName: string ... 1 more field]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val LIMIT = 100\n",
    "val passengers = spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"delimiter\", \",\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(PASSENGER_CSV_PATH)\n",
    "    //--------------------------------------------------------------------------------\n",
    "    // Sort for passengerId match\n",
    "    //--------------------------------------------------------------------------------\n",
    "    .orderBy(asc(\"passengerId\"))\n",
    "    .persist\n",
    "\n",
    "passengers.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent flyer listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequentFlyers.createOrReplaceTempView(\"frequentFlyers\")\n",
    "passengers.createOrReplaceTempView(\"passengers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "queryTopFrequetFlyers = \n",
       "topFrequentFlyers = [passenger_id: int, number_of_flights: bigint ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\n",
       "SELECT\n",
       "    f.passengerId AS passenger_id,\n",
       "    f.numberOfFlights AS number_of_flights,\n",
       "    p.firstName AS first_name,\n",
       "    p.lastName as last_name\n",
       "FROM\n",
       "    frequentFlyers f\n",
       "    INNER JOIN passengers p\n",
       "    ON f.passengerId = p.passengerId\n",
       "ORDER BY number_of_flights DESC\n",
       "\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passenger_id: int, number_of_flights: bigint ... 2 more fields]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val queryTopFrequetFlyers = \"\"\"\n",
    "SELECT \n",
    "    f.passengerId AS passenger_id,\n",
    "    f.numberOfFlights AS number_of_flights,\n",
    "    p.firstName AS first_name,\n",
    "    p.lastName as last_name\n",
    "FROM\n",
    "    frequentFlyers f\n",
    "    INNER JOIN passengers p\n",
    "    ON f.passengerId = p.passengerId\n",
    "ORDER BY number_of_flights DESC\n",
    "\"\"\"\n",
    "val topFrequentFlyers = spark.sql(queryTopFrequetFlyers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------+----------+---------+\n",
      "|passenger_id|number_of_flights|first_name|last_name|\n",
      "+------------+-----------------+----------+---------+\n",
      "|        2068|               32|   Yolande|     Pete|\n",
      "|        4827|               27|     Jaime|    Renay|\n",
      "|        1677|               27| Katherina| Vasiliki|\n",
      "|        3173|               26|  Sunshine|    Scott|\n",
      "|        8961|               26|     Ginny|    Clara|\n",
      "+------------+-----------------+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Query top frequent flyers from flight data. took 4777 ms.\n",
      "\n",
      "(7) MapPartitionsRDD[64] at rdd at <console>:55 []\n",
      " |  MapPartitionsRDD[63] at rdd at <console>:55 []\n",
      " |  MapPartitionsRDD[62] at rdd at <console>:55 []\n",
      " |  ShuffledRowRDD[61] at rdd at <console>:55 []\n",
      " +-(12) MapPartitionsRDD[60] at rdd at <console>:55 []\n",
      "    |   MapPartitionsRDD[56] at rdd at <console>:55 []\n",
      "    |   MapPartitionsRDD[55] at rdd at <console>:55 []\n",
      "    |   MapPartitionsRDD[54] at rdd at <console>:55 []\n",
      "    |   *(2) Sort [passengerId#53 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(passengerId#53 ASC NULLS FIRST, 12)\n",
      "   +- *(1) FileScan csv [passengerId#53,firstName#54,lastName#55] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/masa/home/repository/git/oonisim/spark-programs/dataframe/src/main/r..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<passengerId:int,firstName:string,lastName:string>\n",
      " MapPartitionsRDD[42] at show at <console>:52 []\n",
      "    |       CachedPartitions: 12; MemorySize: 324.3 KB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B\n",
      "    |   MapPartitionsRDD[41] at show at <console>:52 []\n",
      "    |   ShuffledRowRDD[40] at show at <console>:52 []\n",
      "    +-(1) MapPartitionsRDD[39] at show at <console>:52 []\n",
      "       |  MapPartitionsRDD[35] at show at <console>:52 []\n",
      "       |  FileScanRDD[34] at show at <console>:52 []\n"
     ]
    }
   ],
   "source": [
    "timed(\n",
    "    \"Query top frequent flyers from flight data.\",\n",
    "    topFrequentFlyers.show(5)\n",
    ")\n",
    "println(timing)\n",
    "println(topFrequentFlyers.rdd.toDebugString)\n",
    "\n",
    "topFrequentFlyers\n",
    "    // Coalesce to save in the driver node as one file, otherwise no need\n",
    "    .coalesce(1)   \n",
    "    // .persist\n",
    "    .write\n",
    "    .format(\"csv\")\n",
    "    .mode(SaveMode.Overwrite)\n",
    "    .option(\"header\", \"true\")\n",
    "    .save(RESULT_DIR) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "TBD. Need to create test units.\n",
    "\n",
    "### Simple bash test\n",
    "```\n",
    "$ cat flightData.csv | awk '/^139,/{ print }' | wc -w\n",
    "20\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pids = Vector(20, 32)\n",
       "query = \n",
       "flightOf139 = [numberOfFlights: bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\n",
       "SELECT numberOfFlights\n",
       "FROM frequentFlyers\n",
       "WHERE passengerId IN (139, 2068)\n",
       "\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[numberOfFlights: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pids = Vector(20, 32)\n",
    "\n",
    "var query = \"\"\"\n",
    "SELECT numberOfFlights\n",
    "FROM frequentFlyers\n",
    "WHERE passengerId IN (139, 2068)\n",
    "\"\"\"\n",
    "\n",
    "val flightOf139 = spark.sql(query)\n",
    "for((value, index) <- flightOf139.collect().zipWithIndex){\n",
    "    if (pids(index) != value.getLong(0).toInt) println(\"Frequent flyer ID %d has incorrect count %d\".format(index, value))\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[passengerId: int, firstName: string ... 1 more field]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequentFlyers.unpersist\n",
    "passengers.unpersist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
