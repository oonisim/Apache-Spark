{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assumptions\n",
    "1. Data is clearned and not errorneous\n",
    "2. Timezone consideration is not required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.SaveMode\n",
    "import org.apache.spark.sql.functions._\n",
    "import java.time.temporal.ChronoUnit\n",
    "import java.time.{Period, LocalDate, Instant}\n",
    "import java.sql.Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parition control based on core availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NUM_CORES = 4\n",
       "NUM_PARTITIONS = 3\n",
       "spark = <lazy>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<lazy>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val NUM_CORES = 4\n",
    "val NUM_PARTITIONS = 3\n",
    "\n",
    "lazy val spark: SparkSession = SparkSession.builder()\n",
    "    .master(\"local\")\n",
    "    .appName(\"flight\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", NUM_CORES * NUM_PARTITIONS)\n",
    "spark.conf.set(\"spark.default.parallelism\", NUM_CORES * NUM_PARTITIONS)\n",
    "\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FLIGHTDATA_CSV_PATH = ../resources/flightData.csv\n",
       "PASSENGER_CSV_PATH = ../resources/passengers.csv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../resources/passengers.csv"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val FLIGHTDATA_CSV_PATH = \"../resources/flightData.csv\"\n",
    "val PASSENGER_CSV_PATH = \"../resources/passengers.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elapsed time profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timing = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "timed: [T](label: String, code: => T)T\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val timing = new StringBuffer\n",
    "def timed[T](label: String, code: => T): T = {\n",
    "    val start = System.currentTimeMillis()\n",
    "    val result = code\n",
    "    val stop = System.currentTimeMillis()\n",
    "    timing.append(s\"Processing $label took ${stop - start} ms.\\n\")\n",
    "    result\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<console>:78: error: missing argument list for method timed\n",
       "Unapplied methods are only converted to functions when a function type is expected.\n",
       "You can make this conversion explicit by writing `timed _` or `timed(_,_)` instead of `timed`.\n",
       "       timed\n",
       "       ^\n",
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// To flush out error: missing argument list for method timed\n",
    "println(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BASE_LOCALDATE = 2017-01-01\n",
       "udf_months_between = UserDefinedFunction(<function1>,ShortType,Some(List(TimestampType)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "get_months_between: (to: java.sql.Timestamp)Short\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function1>,ShortType,Some(List(TimestampType)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//val BASE_TIMESTAMP = java.sql.Timestamp.valueOf(\"2017-01-01 00:00:00.0\")\n",
    "val BASE_LOCALDATE = LocalDate.parse(\"2017-01-01\").withDayOfMonth(1)\n",
    "\n",
    "def get_months_between(to: Timestamp): Short = {\n",
    "    val monthsBetween = ChronoUnit.MONTHS.between(\n",
    "        BASE_LOCALDATE,\n",
    "        to.toLocalDateTime().toLocalDate().withDayOfMonth(1)\n",
    "    )\n",
    "    monthsBetween.toShort\n",
    "}\n",
    "val udf_months_between = udf((t:Timestamp) => get_months_between(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passengerId: integer (nullable = true)\n",
      " |-- flightId: integer (nullable = true)\n",
      " |-- from: string (nullable = true)\n",
      " |-- to: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- direction: integer (nullable = false)\n",
      " |-- count: integer (nullable = false)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "flightData = [passengerId: int, flightId: int ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, flightId: int ... 5 more fields]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Transformations, no action yet\n",
    "val flightData = spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"delimiter\", \",\")\n",
    "    .option(\"dateFormat\", \"yyyy-MM-dd\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(\"../resources/flightData.csv\")\n",
    "    .withColumn(\n",
    "        \"direction\", \n",
    "        when(lower(col(\"from\")) === \"uk\", 1)\n",
    "        .when(lower(col(\"to\"))   === \"uk\", -1)\n",
    "        .otherwise(0)\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"count\", lit(1)\n",
    "    )\n",
    "    .orderBy(asc(\"passengerId\"), asc(\"date\"))\n",
    "\n",
    "flightData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+----+---+-------------------+---------+-----+\n",
      "|passengerId|flightId|from| to|               date|direction|count|\n",
      "+-----------+--------+----+---+-------------------+---------+-----+\n",
      "|          1|       0|  cg| ir|2017-01-01 00:00:00|        0|    1|\n",
      "|          1|     901|  ir| at|2017-11-29 00:00:00|        0|    1|\n",
      "|          1|     940|  at| cn|2017-12-12 00:00:00|        0|    1|\n",
      "|          1|     972|  cn| ch|2017-12-22 00:00:00|        0|    1|\n",
      "|          1|     993|  ch| pk|2017-12-29 00:00:00|        0|    1|\n",
      "|          2|       0|  cg| ir|2017-01-01 00:00:00|        0|    1|\n",
      "|          3|       0|  cg| ir|2017-01-01 00:00:00|        0|    1|\n",
      "|          3|      32|  ir| sg|2017-01-10 00:00:00|        0|    1|\n",
      "|          3|     108|  sg| be|2017-02-06 00:00:00|        0|    1|\n",
      "|          3|     176|  be| ir|2017-03-05 00:00:00|        0|    1|\n",
      "|          4|       0|  cg| ir|2017-01-01 00:00:00|        0|    1|\n",
      "|          4|     200|  ir| no|2017-03-14 00:00:00|        0|    1|\n",
      "|          4|     561|  no| cn|2017-07-19 00:00:00|        0|    1|\n",
      "|          4|     602|  cn| sg|2017-08-03 00:00:00|        0|    1|\n",
      "|          4|     629|  sg| jo|2017-08-14 00:00:00|        0|    1|\n",
      "|          4|     772|  jo| ir|2017-10-08 00:00:00|        0|    1|\n",
      "|          4|     825|  ir| tj|2017-10-29 00:00:00|        0|    1|\n",
      "|          4|     991|  tj| at|2017-12-29 00:00:00|        0|    1|\n",
      "|          5|       0|  cg| ir|2017-01-01 00:00:00|        0|    1|\n",
      "|          6|       0|  cg| ir|2017-01-01 00:00:00|        0|    1|\n",
      "+-----------+--------+----+---+-------------------+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flightData.createOrReplaceTempView(\"flightData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum over partition & range\n",
    "Number of flights per passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+----+---+-------------------+---------+-----+-----------+\n",
      "|passengerId|flightId|from| to|               date|direction|count|num_flights|\n",
      "+-----------+--------+----+---+-------------------+---------+-----+-----------+\n",
      "|          1|       0|  cg| ir|2017-01-01 00:00:00|        0|    1|          4|\n",
      "|          1|     901|  ir| at|2017-11-29 00:00:00|        0|    1|          3|\n",
      "|          1|     940|  at| cn|2017-12-12 00:00:00|        0|    1|          2|\n",
      "|          1|     972|  cn| ch|2017-12-22 00:00:00|        0|    1|          1|\n",
      "|          1|     993|  ch| pk|2017-12-29 00:00:00|        0|    1|       null|\n",
      "|          2|       0|  cg| ir|2017-01-01 00:00:00|        0|    1|       null|\n",
      "|          3|       0|  cg| ir|2017-01-01 00:00:00|        0|    1|          3|\n",
      "|          3|      32|  ir| sg|2017-01-10 00:00:00|        0|    1|          2|\n",
      "|          3|     108|  sg| be|2017-02-06 00:00:00|        0|    1|          1|\n",
      "|          3|     176|  be| ir|2017-03-05 00:00:00|        0|    1|       null|\n",
      "|          4|       0|  cg| ir|2017-01-01 00:00:00|        0|    1|          7|\n",
      "|          4|     200|  ir| no|2017-03-14 00:00:00|        0|    1|          6|\n",
      "|          4|     561|  no| cn|2017-07-19 00:00:00|        0|    1|          5|\n",
      "|          4|     602|  cn| sg|2017-08-03 00:00:00|        0|    1|          4|\n",
      "|          4|     629|  sg| jo|2017-08-14 00:00:00|        0|    1|          3|\n",
      "|          4|     772|  jo| ir|2017-10-08 00:00:00|        0|    1|          2|\n",
      "|          4|     825|  ir| tj|2017-10-29 00:00:00|        0|    1|          1|\n",
      "|          4|     991|  tj| at|2017-12-29 00:00:00|        0|    1|       null|\n",
      "|          5|       0|  cg| ir|2017-01-01 00:00:00|        0|    1|       null|\n",
      "|          6|       0|  cg| ir|2017-01-01 00:00:00|        0|    1|          9|\n",
      "+-----------+--------+----+---+-------------------+---------+-----+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "query = \n",
       "countSum = [passengerId: int, flightId: int ... 6 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n",
       "\"\n",
       "SELECT\n",
       "    f.*,\n",
       "    sum(count) OVER (\n",
       "        PARTITION BY passengerId\n",
       "        ORDER BY\n",
       "            passengerId ASC,\n",
       "            date DESC\n",
       "        ROWS BETWEEN\n",
       "            UNBOUNDED PRECEDING\n",
       "            AND\n",
       "            1 PRECEDING\n",
       "    ) as num_flights\n",
       "FROM\n",
       "    flightData f\n",
       "ORDER BY\n",
       "    passengerId, date\n",
       "\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, flightId: int ... 6 more fields]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var query = \"\"\"\n",
    "SELECT \n",
    "    f.*,\n",
    "    sum(count) OVER (\n",
    "        PARTITION BY passengerId \n",
    "        ORDER BY \n",
    "            passengerId ASC, \n",
    "            date DESC\n",
    "        ROWS BETWEEN \n",
    "            UNBOUNDED PRECEDING\n",
    "            AND \n",
    "            1 PRECEDING\n",
    "    ) as num_flights\n",
    "FROM\n",
    "    flightData f\n",
    "ORDER BY \n",
    "    passengerId, date\n",
    "\"\"\"\n",
    "\n",
    "val countSum = spark.sql(query)\n",
    "countSum.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lag / Lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+---------+------------------+\n",
      "|LAG_FROM_PREVIOUS_ROW|ROW_VALUE|LEAD_FROM_NEXT_ROW|\n",
      "+---------------------+---------+------------------+\n",
      "|                 null|        1|                 2|\n",
      "|                    1|        2|                 3|\n",
      "|                    2|        3|                 4|\n",
      "|                    3|        4|              null|\n",
      "+---------------------+---------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "query = \n",
       "result = [LAG_FROM_PREVIOUS_ROW: int, ROW_VALUE: int ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\n",
       "SELECT\n",
       "  lag(v) OVER (ORDER BY v) as LAG_FROM_PREVIOUS_ROW,\n",
       "  v as ROW_VALUE,\n",
       "  lead(v) OVER (ORDER BY v) as LEAD_FROM_NEXT_ROW\n",
       "FROM (\n",
       "  VALUES (1), (2), (3), (4)\n",
       ") t(v)\n",
       "\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[LAG_FROM_PREVIOUS_ROW: int, ROW_VALUE: int ... 1 more field]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var query = \"\"\"\n",
    "SELECT\n",
    "  lag(v) OVER (ORDER BY v) as LAG_FROM_PREVIOUS_ROW,\n",
    "  v as ROW_VALUE,\n",
    "  lead(v) OVER (ORDER BY v) as LEAD_FROM_NEXT_ROW\n",
    "FROM (\n",
    "  VALUES (1), (2), (3), (4)\n",
    ") t(v)\n",
    "\"\"\"\n",
    "var result = spark.sql(query)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row Number in Window Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+----+---+-------------------+---------+-----+---+\n",
      "|passengerId|flightId|from| to|               date|direction|count|seq|\n",
      "+-----------+--------+----+---+-------------------+---------+-----+---+\n",
      "|          1|       0|  cg| ir|2017-01-01 00:00:00|        0|    1|  1|\n",
      "|          1|     901|  ir| at|2017-11-29 00:00:00|        0|    1|  2|\n",
      "|          1|     940|  at| cn|2017-12-12 00:00:00|        0|    1|  3|\n",
      "|          1|     972|  cn| ch|2017-12-22 00:00:00|        0|    1|  4|\n",
      "|          1|     993|  ch| pk|2017-12-29 00:00:00|        0|    1|  5|\n",
      "|          2|       0|  cg| ir|2017-01-01 00:00:00|        0|    1|  1|\n",
      "|          3|       0|  cg| ir|2017-01-01 00:00:00|        0|    1|  1|\n",
      "|          3|      32|  ir| sg|2017-01-10 00:00:00|        0|    1|  2|\n",
      "|          3|     108|  sg| be|2017-02-06 00:00:00|        0|    1|  3|\n",
      "|          3|     176|  be| ir|2017-03-05 00:00:00|        0|    1|  4|\n",
      "|          4|       0|  cg| ir|2017-01-01 00:00:00|        0|    1|  1|\n",
      "|          4|     200|  ir| no|2017-03-14 00:00:00|        0|    1|  2|\n",
      "|          4|     561|  no| cn|2017-07-19 00:00:00|        0|    1|  3|\n",
      "|          4|     602|  cn| sg|2017-08-03 00:00:00|        0|    1|  4|\n",
      "|          4|     629|  sg| jo|2017-08-14 00:00:00|        0|    1|  5|\n",
      "|          4|     772|  jo| ir|2017-10-08 00:00:00|        0|    1|  6|\n",
      "|          4|     825|  ir| tj|2017-10-29 00:00:00|        0|    1|  7|\n",
      "|          4|     991|  tj| at|2017-12-29 00:00:00|        0|    1|  8|\n",
      "|          5|       0|  cg| ir|2017-01-01 00:00:00|        0|    1|  1|\n",
      "|          6|       0|  cg| ir|2017-01-01 00:00:00|        0|    1|  1|\n",
      "+-----------+--------+----+---+-------------------+---------+-----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "query = \n",
       "passageSequenced = [passengerId: int, flightId: int ... 6 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\n",
       "SELECT\n",
       "    f.*,\n",
       "    ROW_NUMBER() OVER (PARTITION BY passengerId ORDER BY passengerId, date) as seq\n",
       "FROM\n",
       "    flightData f\n",
       "ORDER BY\n",
       "    passengerId, date\n",
       "\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, flightId: int ... 6 more fields]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var query = \"\"\"\n",
    "SELECT \n",
    "    f.*,\n",
    "    ROW_NUMBER() OVER (PARTITION BY passengerId ORDER BY passengerId, date) as seq \n",
    "FROM\n",
    "    flightData f\n",
    "ORDER BY \n",
    "    passengerId, date\n",
    "\"\"\"\n",
    "\n",
    "val passageSequenced = spark.sql(query)\n",
    "passageSequenced.show()\n",
    "passageSequenced.createOrReplaceTempView(\"passageSequenced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAG / LEAD \n",
    "Flights starting and ending at UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12) MapPartitionsRDD[2086] at rdd at <console>:136 []\n",
      " |   MapPartitionsRDD[2085] at rdd at <console>:136 []\n",
      " |   MapPartitionsRDD[2084] at rdd at <console>:136 []\n",
      " |   ShuffledRowRDD[2083] at rdd at <console>:136 []\n",
      " +-(12) MapPartitionsRDD[2082] at rdd at <console>:136 []\n",
      "    |   MapPartitionsRDD[2078] at rdd at <console>:136 []\n",
      "    |   ShuffledRowRDD[2077] at rdd at <console>:136 []\n",
      "    +-(12) MapPartitionsRDD[2076] at rdd at <console>:136 []\n",
      "       |   MapPartitionsRDD[2075] at rdd at <console>:136 []\n",
      "       |   ShuffledRowRDD[2074] at rdd at <console>:136 []\n",
      "       +-(12) MapPartitionsRDD[2073] at rdd at <console>:136 []\n",
      "          |   MapPartitionsRDD[2069] at rdd at <console>:136 []\n",
      "          |   MapPartitionsRDD[2068] at rdd at <console>:136 []\n",
      "          |   MapPartitionsRDD[2067] at rdd at <console>:136 []\n",
      "          |   ShuffledRowRDD[2066] at rdd at <console>:136 []\n",
      "          +-(12) MapPartitionsRDD[2065] at rdd at <console>:136 []\n",
      "             |   MapPartitionsRDD[2064] at rdd at <console>:136 []\n",
      "             |   ShuffledRowRDD[2063] at rdd at <console>:136 []\n",
      "             +-(12) MapPartitionsRDD[2062] at rdd at <console>:136 []\n",
      "                |   MapPartitionsRDD[2058] at rdd at <console>:136 []\n",
      "                |   MapPartitionsRDD[2057] at rdd at <console>:136 []\n",
      "                |   MapPartitionsRDD[2056] at rdd at <console>:136 []\n",
      "                |   ShuffledRowRDD[2055] at rdd at <console>:136 []\n",
      "                +-(12) MapPartitionsRDD[2054] at rdd at <console>:136 []\n",
      "                   |   MapPartitionsRDD[2053] at rdd at <console>:136 []\n",
      "                   |   ShuffledRowRDD[2052] at rdd at <console>:136 []\n",
      "                   +-(1) MapPartitionsRDD[2051] at rdd at <console>:136 []\n",
      "                      |  MapPartitionsRDD[2047] at rdd at <console>:136 []\n",
      "                      |  FileScanRDD[2046] at rdd at <console>:136 []\n",
      "+-----------+---------+\n",
      "|passengerId|countries|\n",
      "+-----------+---------+\n",
      "|         22|        4|\n",
      "|         53|        4|\n",
      "|        167|        2|\n",
      "|        204|        3|\n",
      "|        227|        1|\n",
      "+-----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "queryVisitedCountries = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\n",
       "WITH closedPassages AS(\n",
       "    SELECT\n",
       "        passengerId,\n",
       "        from, to,\n",
       "        direction,\n",
       "        seq,\n",
       "        --------------------------------------------------------------------------------\n",
       "        -- For a departure flight, take the the return flight, if there is, seq num\n",
       "        --------------------------------------------------------------------------------\n",
       "        CASE\n",
       "            WHEN direction == 1\n",
       "            THEN lead(seq) OVER (PARTITION BY passengerId ORDER BY seq)\n",
       "        END AS return,\n",
       "        --------------------------------------------------------------------------------\n",
       "        -- For a departure flight, count the visiting countries, if returned.\n",
       "        --------------------------------------------------------------------------------...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val queryVisitedCountries = \"\"\"\n",
    "WITH closedPassages AS(\n",
    "    SELECT \n",
    "        passengerId, \n",
    "        from, to, \n",
    "        direction, \n",
    "        seq,\n",
    "        -------------------------------------------------------------------------------- \n",
    "        -- For a departure flight, take the the return flight, if there is, seq num\n",
    "        -------------------------------------------------------------------------------- \n",
    "        CASE \n",
    "            WHEN direction == 1\n",
    "            THEN lead(seq) OVER (PARTITION BY passengerId ORDER BY seq)\n",
    "        END AS return,\n",
    "        -------------------------------------------------------------------------------- \n",
    "        -- For a departure flight, count the visiting countries, if returned.\n",
    "        -------------------------------------------------------------------------------- \n",
    "        CASE \n",
    "            WHEN direction == 1\n",
    "            THEN lead(seq) OVER (PARTITION BY passengerId ORDER BY seq) - seq\n",
    "        END AS countries\n",
    "    FROM passageSequenced p\n",
    "    WHERE \n",
    "        direction != 0\n",
    "        AND EXISTS (  \n",
    "            SELECT passengerId\n",
    "            FROM\n",
    "                passageSequenced\n",
    "            WHERE \n",
    "                direction != 0 AND\n",
    "                passengerId == p.passengerId\n",
    "            GROUP BY\n",
    "                passengerId\n",
    "            Having count(DISTINCT direction) == 2\n",
    "        )\n",
    "    ORDER BY \n",
    "        passengerId, seq\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    passengerId,\n",
    "    max(countries) as countries\n",
    "FROM closedPassages\n",
    "WHERE \n",
    "    countries IS NOT NULL\n",
    "GROUP BY \n",
    "    passengerId\n",
    "ORDER BY \n",
    "    passengerId\n",
    "\"\"\"\n",
    "\n",
    "/*\n",
    "val closedPassages = spark.sql(closedPassageQuery)\n",
    "closedPassages.show()\n",
    "closedPassages.createOrReplaceTempView(\"closedPassages\")\n",
    "*/\n",
    "\n",
    "val visitedCountries = spark.sql(queryVisitedCountries)\n",
    "println(visitedCountries.rdd.toDebugString)\n",
    "visitedCountries.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
