{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 21 - Streaming  Aggregation\n",
    "Run aggregation on streaming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.linalg._\n",
    "import org.apache.spark.mllib.linalg.distributed._\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.sql.Row\n",
    "\n",
    "import org.apache.spark.sql.expressions._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.SaveMode\n",
    "import org.apache.spark.sql.DataFrame\n",
    "\n",
    "import org.apache.spark.sql.streaming.Trigger\n",
    "\n",
    "import java.time.temporal.ChronoUnit\n",
    "import java.time.{Period, LocalDate, Instant}\n",
    "import java.sql.Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- To left align the HTML components in Markdown -->\n",
       "<style>\n",
       "table {float:left}\n",
       "</style>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%html\n",
    "<!-- To left align the HTML components in Markdown -->\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark parition control based on core availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NUM_CORES = 4\n",
       "NUM_PARTITIONS = 3\n",
       "spark = <lazy>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<lazy>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val NUM_CORES = 4\n",
    "val NUM_PARTITIONS = 3\n",
    "\n",
    "lazy val spark: SparkSession = SparkSession.builder()\n",
    "    .appName(\"streaming\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.default.parallelism\", NUM_CORES * NUM_PARTITIONS)\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", NUM_CORES * NUM_PARTITIONS)\n",
    "/*\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", NUM_CORES * NUM_PARTITIONS)\n",
    "spark.conf.set(\"spark.default.parallelism\", NUM_CORES * NUM_PARTITIONS)\n",
    "spark.conf.set(\"spark.driver.memory\", \"6g\")\n",
    "spark.conf.set(\"spark.executor.memory\", \"2g\")\n",
    "spark.conf.set(\"spark.master\", \"spark://oonisim:7077\")\n",
    "*/\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(spark.serializer,org.apache.spark.serializer.KryoSerializer)\n",
      "(spark.driver.host,172.17.0.1)\n",
      "(spark.eventLog.enabled,true)\n",
      "(spark.driver.port,40563)\n",
      "(spark.hadoop.validateOutputSpecs,True)\n",
      "(spark.repl.class.uri,spark://172.17.0.1:40563/classes)\n",
      "(spark.jars,file:/home/oonisim/.local/share/jupyter/kernels/apache_toree_scala/lib/toree-assembly-0.3.0-incubating.jar)\n",
      "(spark.repl.class.outputDir,/tmp/spark-802b15dd-23c3-445d-b645-f32c29b463c9/repl-9298f6a6-1b0d-4ace-b4cd-d186b70da1f2)\n",
      "(spark.app.name,streaming)\n",
      "(spark.driver.memory,3g)\n",
      "(spark.executor.instances,2)\n",
      "(spark.history.fs.logdirectory,hdfs://oonisim:8020/logs_spark)\n",
      "(spark.default.parallelism,12)\n",
      "(spark.executor.id,driver)\n",
      "(spark.submit.deployMode,client)\n",
      "(spark.master,yarn)\n",
      "(spark.ui.filters,org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter)\n",
      "(spark.executor.memory,4g)\n",
      "(spark.eventLog.dir,hdfs://oonisim:8020/logs_spark)\n",
      "(spark.executor.cores,4)\n",
      "(spark.driver.appUIAddress,http://172.17.0.1:4040)\n",
      "(spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS,oonisim)\n",
      "(spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES,http://oonisim:8088/proxy/application_1576122573478_0016)\n",
      "(spark.app.id,application_1576122573478_0016)\n",
      "(spark.sql.shuffle.partitions,12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "configMap: Unit = ()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val configMap = spark.conf.getAll.foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PROTOCOL = file://\n",
       "DATA_DIR = /home/oonisim/home/repositories/git/oonisim/spark-programs/Streaming\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/home/oonisim/home/repositories/git/oonisim/spark-programs/Streaming"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val PROTOCOL=\"file://\"\n",
    "val DATA_DIR=\"/home/oonisim/home/repositories/git/oonisim/spark-programs/Streaming/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema from Dataframe\n",
    "Retrieve the data schema from DataFrame.\n",
    "\n",
    "Structured Streaming does not let you perform schema inference without explicitly enabling it. You can enable schema inference for this by setting the configuration spark.sql.streaming.schemaInference to true. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "static = [Arrival_Time: bigint, Creation_Time: bigint ... 8 more fields]\n",
       "dataSchema = StructType(StructField(Arrival_Time,LongType,true), StructField(Creation_Time,LongType,true), StructField(Device,StringType,true), StructField(Index,LongType,true), StructField(Model,StringType,true), StructField(User,StringType,true), StructField(gt,StringType,true), StructField(x,DoubleType,true), StructField(y,DoubleType,true), StructField(z,DoubleType,true))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StructType(StructField(Arrival_Time,LongType,true), StructField(Creation_Time,LongType,true), StructField(Device,StringType,true), StructField(Index,LongType,true), StructField(Model,StringType,true), StructField(User,StringType,true), StructField(gt,StringType,true), StructField(x,DoubleType,true), StructField(y,DoubleType,true), StructField(z,DoubleType,true))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val static = spark.read.json(PROTOCOL + DATA_DIR + \"/activity-data/\")\n",
    "val dataSchema = static.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructField(Arrival_Time,LongType,true)\n",
      "StructField(Creation_Time,LongType,true)\n",
      "StructField(Device,StringType,true)\n",
      "StructField(Index,LongType,true)\n",
      "StructField(Model,StringType,true)\n",
      "StructField(User,StringType,true)\n",
      "StructField(gt,StringType,true)\n",
      "StructField(x,DoubleType,true)\n",
      "StructField(y,DoubleType,true)\n",
      "StructField(z,DoubleType,true)\n"
     ]
    }
   ],
   "source": [
    "dataSchema.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+--------+-----+------+----+-----+------------+------------+------------+\n",
      "| Arrival_Time|      Creation_Time|  Device|Index| Model|User|   gt|           x|           y|           z|\n",
      "+-------------+-------------------+--------+-----+------+----+-----+------------+------------+------------+\n",
      "|1424686735090|1424686733090638193|nexus4_1|   18|nexus4|   g|stand| 3.356934E-4|-5.645752E-4|-0.018814087|\n",
      "|1424686735292|1424688581345918092|nexus4_2|   66|nexus4|   g|stand|-0.005722046| 0.029083252| 0.005569458|\n",
      "|1424686735500|1424686733498505625|nexus4_1|   99|nexus4|   g|stand|   0.0078125|-0.017654419| 0.010025024|\n",
      "+-------------+-------------------+--------+-----+------+----+-----+------------+------------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "static.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "streaming = [Arrival_Time: bigint, Creation_Time: bigint ... 8 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Arrival_Time: bigint, Creation_Time: bigint ... 8 more fields]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val streaming = spark\n",
    "    .readStream\n",
    "    .schema(dataSchema)\n",
    "    .option(\"maxFilesPerTrigger\", 1)\n",
    "    .json(PROTOCOL + DATA_DIR + \"/activity-data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ouput Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deviceModelStats = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@3fa2d26c\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@3fa2d26c"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val deviceModelStats = streaming\n",
    "    .cube(\"gt\", \"model\").avg()\n",
    "    .drop(\"avg(Arrival_time)\")\n",
    "    .drop(\"avg(Creation_Time)\")\n",
    "    .drop(\"avg(Index)\")\n",
    "    .writeStream\n",
    "    .queryName(\"device_counts\")\n",
    "    .format(\"memory\")\n",
    "    .outputMode(\"complete\")\n",
    "    .trigger(Trigger.ProcessingTime(1000))\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@3fa2d26c)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.streams.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+------+------+\n",
      "| gt|model|avg(x)|avg(y)|avg(z)|\n",
      "+---+-----+------+------+------+\n",
      "+---+-----+------+------+------+\n",
      "\n",
      "+---+-----+------+------+------+\n",
      "| gt|model|avg(x)|avg(y)|avg(z)|\n",
      "+---+-----+------+------+------+\n",
      "+---+-----+------+------+------+\n",
      "\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|        gt| model|              avg(x)|              avg(y)|              avg(z)|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|      null|nexus4|1.966600070764429...|-0.00625396643444789|-0.01041804405820...|\n",
      "|stairsdown|nexus4|0.019154391360635455|-0.03176165816067268| 0.11931218905160704|\n",
      "|     stand|nexus4|-8.48276359097096...|1.633235242677092...|-2.53727045751175...|\n",
      "|      bike|  null|0.021842310709212158|-0.00921752557466...|-0.08129998643162427|\n",
      "|      bike|nexus4|0.021842310709212158|-0.00921752557466...|-0.08129998643162427|\n",
      "|      null|  null|1.966600070764429...|-0.00625396643444789|-0.01041804405820...|\n",
      "|stairsdown|  null|0.019154391360635455|-0.03176165816067268| 0.11931218905160704|\n",
      "|       sit|  null|-4.24413275568737...|3.901181913470919E-4|-2.25793020279493...|\n",
      "|     stand|  null|-8.48276359097096...|1.633235242677092...|-2.53727045751175...|\n",
      "|      null|  null|-0.00691928240914...|-2.32029237315700...|0.001430477722630...|\n",
      "|      walk|  null|-0.00479134726232...|-0.00108929050008...|-0.00104180344128...|\n",
      "|  stairsup|  null|-0.02465908809689655|-0.00792855262818...|-0.10020874972913418|\n",
      "|      walk|nexus4|-0.00479134726232...|-0.00108929050008...|-0.00104180344128...|\n",
      "|       sit|nexus4|-4.24413275568737...|3.901181913470919E-4|-2.25793020279493...|\n",
      "|  stairsup|nexus4|-0.02465908809689...|-0.00792855262818...|-0.10020874972913418|\n",
      "|      null|nexus4|-0.00691928240914...|-2.32029237315700...|0.001430477722630...|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|        gt| model|              avg(x)|              avg(y)|              avg(z)|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|      null|nexus4|-3.29032447123288...|-0.00595936497260...|-0.01044173681787...|\n",
      "|stairsdown|nexus4|0.018546590257791686|-0.02886561996713...| 0.11976036154397048|\n",
      "|     stand|nexus4|-1.35119933244763...|6.012609151258311...|6.441199255566755...|\n",
      "|      bike|  null|0.020103125841378744|-0.00864490503699518|-0.08093887457270509|\n",
      "|      bike|nexus4|0.020103125841378744|-0.00864490503699518|-0.08093887457270509|\n",
      "|      null|  null|-3.29032447123288...|-0.00595936497260...|-0.01044173681787...|\n",
      "|stairsdown|  null|0.018546590257791686|-0.02886561996713...| 0.11976036154397048|\n",
      "|       sit|  null|-4.67236140756841...|3.061843308992308...|-2.50357155698647E-4|\n",
      "|     stand|  null|-1.35119933244763...|6.012609151258313E-5|6.441199255566775E-6|\n",
      "|      null|  null|-0.00682986052053...|-0.00144621415849...|-4.91404367149051...|\n",
      "|      walk|  null|-0.00591583277832...|-8.92750231991708...|-6.52167587397219...|\n",
      "|  stairsup|  null|-0.02479492820284...|-0.00753282817292...|-0.10044577693005423|\n",
      "|      walk|nexus4|-0.00591583277832...|-8.92750231991708...|-6.52167587397218...|\n",
      "|       sit|nexus4|-4.67236140756841...|3.061843308992308...|-2.50357155698646...|\n",
      "|  stairsup|nexus4|-0.02479492820284...|-0.00753282817292459|-0.10044577693005423|\n",
      "|      null|nexus4|-0.00682986052053...|-0.00144621415849...|-4.91404367149034...|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|        gt| model|              avg(x)|              avg(y)|              avg(z)|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|      null|nexus4|-2.63479054430272...|-0.00609223485212...|-0.01014704687720...|\n",
      "|stairsdown|nexus4| 0.02036595063430258|-0.03212144019946603| 0.12219752459958645|\n",
      "|     stand|nexus4|-1.43252290426894...|1.584934644042063...|-9.72494136964815...|\n",
      "|      bike|  null|0.020263214868013656|-0.00791950269960...|-0.08246076246339307|\n",
      "|      bike|nexus4|0.020263214868013656|-0.00791950269960...|-0.08246076246339307|\n",
      "|      null|  null|-2.63479054430272...|-0.00609223485212...|-0.01014704687720...|\n",
      "|stairsdown|  null| 0.02036595063430258|-0.03212144019946603| 0.12219752459958645|\n",
      "|       sit|  null|-4.88451627775199...|3.001762388516188E-4|-2.04692992136357...|\n",
      "|     stand|  null|-1.43252290426894...|1.584934644042063...|-9.72494136964815...|\n",
      "|      null|  null|-0.00733915242482...| 1.80112323577512E-4|3.954706582422812...|\n",
      "|      walk|  null|-0.00605055359369...|2.681635732688809E-4|3.355038996367949E-4|\n",
      "|  stairsup|  null|-0.02539100569502...|-0.00955454274557...| -0.1004595159849689|\n",
      "|      walk|nexus4|-0.00605055359369...|2.681635732688808E-4|3.355038996367948...|\n",
      "|       sit|nexus4|-4.88451627775199...|3.001762388516188E-4|-2.04692992136357...|\n",
      "|  stairsup|nexus4|-0.02539100569502...|-0.00955454274557...| -0.1004595159849689|\n",
      "|      null|nexus4|-0.00733915242482...| 1.80112323577512E-4|3.954706582422811E-4|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|        gt| model|              avg(x)|              avg(y)|              avg(z)|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|      null|nexus4|9.101928423916747E-5|-0.00577701764070...|-0.01051128987958...|\n",
      "|stairsdown|nexus4|0.020618158557989562|-0.03170897756345616|  0.1196754639802105|\n",
      "|     stand|nexus4|-1.80012670402481...|1.278145409411127...|-2.27404829960298...|\n",
      "|      bike|  null| 0.02147165413101994|-0.00796544997570...|-0.08254972309900703|\n",
      "|      bike|nexus4| 0.02147165413101994|-0.00796544997570...|-0.08254972309900703|\n",
      "|      null|  null|9.101928423916743E-5|-0.00577701764070...|-0.01051128987958...|\n",
      "|stairsdown|  null|0.020618158557989562|-0.03170897756345616|  0.1196754639802105|\n",
      "|       sit|  null|-5.20978178048424...|2.297981304988632...|-2.54252618726032...|\n",
      "|     stand|  null|-1.80012670402481...|1.278145409411127...|-2.27404829960297...|\n",
      "|      null|  null|-0.00739639660352...|-2.99498006019126...|8.956936396086728E-4|\n",
      "|      walk|  null|-0.00539961510237...|8.253480370478195E-4|-7.12524955768686...|\n",
      "|  stairsup|  null|-0.02490774268688...|-0.00763549171116455|-0.10082523336312156|\n",
      "|      walk|nexus4|-0.00539961510237...|8.253480370478195E-4|-7.12524955768687E-5|\n",
      "|       sit|nexus4|-5.20978178048424...|2.297981304988632...|-2.54252618726032...|\n",
      "|  stairsup|nexus4|-0.02490774268688...|-0.00763549171116...|-0.10082523336312156|\n",
      "|      null|nexus4|-0.00739639660352...|-2.99498006019126...|8.956936396086728E-4|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|        gt| model|              avg(x)|              avg(y)|              avg(z)|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|      null|nexus4|2.055434566880441...|-0.00581469138404...|-0.01017930467601...|\n",
      "|stairsdown|nexus4|0.020576057939885557|-0.03209151166932783|  0.1197015782605745|\n",
      "|     stand|nexus4|-2.26642939862971...|1.466903605220588...|-9.61067104448345E-6|\n",
      "|      bike|  null| 0.02180846359763351|-0.00794160559098...|-0.08231738739967731|\n",
      "|      bike|nexus4| 0.02180846359763351|-0.00794160559098...|-0.08231738739967731|\n",
      "|      null|  null|2.055434566880441...|-0.00581469138404...|-0.01017930467601...|\n",
      "|stairsdown|  null|0.020576057939885557|-0.03209151166932783|  0.1197015782605745|\n",
      "|       sit|  null|-5.37092577681486...|2.239553575370019E-4|-2.76196922159407...|\n",
      "|     stand|  null|-2.26642939862971...|1.466903605220588...|-9.61067104448342...|\n",
      "|      null|  null|-0.00757522464677...|-1.65744212908321...|0.002169138656072457|\n",
      "|      walk|  null|-0.00476698434096...|0.001083635718464...|2.705417273896004E-4|\n",
      "|  stairsup|  null|-0.02491744173369634|-0.00807352896103...|-0.10030820537323629|\n",
      "|      walk|nexus4|-0.00476698434096...|0.001083635718464...|2.705417273896004...|\n",
      "|       sit|nexus4|-5.37092577681486...|2.239553575370019E-4|-2.76196922159407...|\n",
      "|  stairsup|nexus4|-0.02491744173369634|-0.00807352896103...|-0.10030820537323629|\n",
      "|      null|nexus4|-0.00757522464677...|-1.65744212908321...|0.002169138656072...|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|        gt| model|              avg(x)|              avg(y)|              avg(z)|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|      null|nexus4|3.039784181153491...|-0.00627429121078...|-0.01007703072928...|\n",
      "|stairsdown|nexus4| 0.02134421704386846|-0.03347021100214...| 0.12025228147479891|\n",
      "|     stand|nexus4|-2.33770092167197...|2.221805099707795...|2.148314301834639E-5|\n",
      "|      bike|  null|0.022021064927427263|-0.00857823575364...|-0.08239714732207502|\n",
      "|      bike|nexus4|0.022021064927427263|-0.00857823575364...|-0.08239714732207502|\n",
      "|      null|  null|3.039784181153491...|-0.00627429121078...|-0.01007703072928...|\n",
      "|stairsdown|  null| 0.02134421704386846|-0.03347021100214...| 0.12025228147479891|\n",
      "|       sit|  null|-5.23942285199871E-4|1.952689407138996E-4|-2.53405830516196...|\n",
      "|     stand|  null|-2.33770092167197...|2.221805099707795...|2.148314301834641...|\n",
      "|      null|  null|-0.00772323892740...|-2.37808288647952...|0.002483448574519312|\n",
      "|      walk|  null|-0.00469299246537...|3.856683724802827...|1.098881191065793...|\n",
      "|  stairsup|  null|-0.02504398555256...|-0.00870346614366...|-0.10012182542373474|\n",
      "|      walk|nexus4|-0.00469299246537...|3.856683724802828...|1.098881191065792...|\n",
      "|       sit|nexus4|-5.23942285199871E-4|1.952689407138996E-4|-2.53405830516196...|\n",
      "|  stairsup|nexus4|-0.02504398555256838|-0.00870346614366...|-0.10012182542373474|\n",
      "|      null|nexus4|-0.00772323892740...|-2.37808288647952...|0.002483448574519...|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|        gt| model|              avg(x)|              avg(y)|              avg(z)|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|      null|nexus4|5.592320438258541E-4|-0.00622589467238294|-0.01015675124571...|\n",
      "|stairsdown|nexus4|0.021943396653192813|-0.03402074295849328| 0.12030686384317511|\n",
      "|     stand|nexus4|-2.57489646126369...|2.393335893858213...|7.048116618600043E-5|\n",
      "|      bike|  null|0.022259827657402118|-0.00871530874202...|-0.08198820314449606|\n",
      "|      bike|nexus4|0.022259827657402118|-0.00871530874202...|-0.08198820314449606|\n",
      "|      null|  null|5.592320438258541E-4|-0.00622589467238294|-0.01015675124571...|\n",
      "|stairsdown|  null|0.021943396653192813|-0.03402074295849328| 0.12030686384317511|\n",
      "|       sit|  null|-5.25874400958727E-4|1.930247399907023...|-2.00756079274998...|\n",
      "|     stand|  null|-2.57489646126369...|2.393335893858213...|7.048116618600046E-5|\n",
      "|      null|  null|-0.00742158046833...|-1.80163503738447...|0.002325752688125776|\n",
      "|      walk|  null|-0.00442564299765...|9.694735507181491E-4|-2.81606857582389...|\n",
      "|  stairsup|  null|-0.02453717074497...|-0.00852095150651...|-0.10065914895602084|\n",
      "|      walk|nexus4|-0.00442564299765...|9.694735507181491E-4|-2.81606857582389...|\n",
      "|       sit|nexus4|-5.25874400958727E-4|1.930247399907023...|-2.00756079274998...|\n",
      "|  stairsup|nexus4|-0.02453717074497...|-0.00852095150651...|-0.10065914895602084|\n",
      "|      null|nexus4| -0.0074215804683386|-1.80163503738447...|0.002325752688125776|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Name: java.lang.InterruptedException\n",
       "Message: sleep interrupted\n",
       "StackTrace:   at java.lang.Thread.sleep(Native Method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while(deviceModelStats.isActive){\n",
    "    spark.sql(\"SELECT * FROM device_counts\").show(false)\n",
    "    Thread.sleep(3000)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wait for Streaming termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Name: org.apache.spark.sql.streaming.StreamingQueryException\n",
       "Message: Query device_counts [id = 1e90c9ce-db90-4200-9851-d1540e183c89, runId = b9ae7752-d3e1-4e06-82a5-3163cc705496] terminated with exception: Job 61 cancelled because SparkContext was shut down\n",
       "StackTrace:   at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:297)\n",
       "  at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:193)\n",
       "Caused by: org.apache.spark.SparkException: Job 61 cancelled because SparkContext was shut down\n",
       "  at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:932)\n",
       "  at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:930)\n",
       "  at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)\n",
       "  at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:930)\n",
       "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2128)\n",
       "  at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)\n",
       "  at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2041)\n",
       "  at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)\n",
       "  at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)\n",
       "  at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)\n",
       "  at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend$MonitorThread.run(YarnClientSchedulerBackend.scala:121)\n",
       "  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n",
       "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n",
       "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n",
       "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n",
       "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n",
       "  at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n",
       "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
       "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
       "  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n",
       "  at org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n",
       "  at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:299)\n",
       "  at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3389)\n",
       "  at org.apache.spark.sql.Dataset$$anonfun$collect$1.apply(Dataset.scala:2788)\n",
       "  at org.apache.spark.sql.Dataset$$anonfun$collect$1.apply(Dataset.scala:2788)\n",
       "  at org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\n",
       "  at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n",
       "  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n",
       "  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n",
       "  at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\n",
       "  at org.apache.spark.sql.Dataset.collect(Dataset.scala:2788)\n",
       "  at org.apache.spark.sql.execution.streaming.MemorySink.addBatch(memory.scala:280)\n",
       "  at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch$5$$anonfun$apply$17.apply(MicroBatchExecution.scala:537)\n",
       "  at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n",
       "  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n",
       "  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n",
       "  at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch$5.apply(MicroBatchExecution.scala:535)\n",
       "  at org.apache.spark.sql.execution.streaming.ProgressReporter$class.reportTimeTaken(ProgressReporter.scala:351)\n",
       "  at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:58)\n",
       "  at org.apache.spark.sql.execution.streaming.MicroBatchExecution.org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch(MicroBatchExecution.scala:534)\n",
       "  at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply$mcV$sp(MicroBatchExecution.scala:198)\n",
       "  at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply(MicroBatchExecution.scala:166)\n",
       "  at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply(MicroBatchExecution.scala:166)\n",
       "  at org.apache.spark.sql.execution.streaming.ProgressReporter$class.reportTimeTaken(ProgressReporter.scala:351)\n",
       "  at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:58)\n",
       "  at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1.apply$mcZ$sp(MicroBatchExecution.scala:166)\n",
       "  at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:56)\n",
       "  at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:160)\n",
       "  at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:281)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Must specify to wait for the termination of the query using activityQuery.awaitTermination() \n",
    "// to prevent the driver process from exiting while the query is active.\n",
    "// This function will block the thread.\n",
    "deviceModelStats.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
