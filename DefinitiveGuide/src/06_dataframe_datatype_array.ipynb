{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 - Complex Structure - Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.linalg._\n",
    "import org.apache.spark.mllib.linalg.distributed._\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.sql.Row\n",
    "\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.SaveMode\n",
    "import org.apache.spark.sql.DataFrame\n",
    "\n",
    "import java.time.temporal.ChronoUnit\n",
    "import java.time.{Period, LocalDate, Instant}\n",
    "import java.sql.Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark parition control based on core availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NUM_CORES = 2\n",
       "NUM_PARTITIONS = 2\n",
       "spark = <lazy>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<lazy>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val NUM_CORES = 2\n",
    "val NUM_PARTITIONS = 2\n",
    "\n",
    "lazy val spark: SparkSession = SparkSession.builder()\n",
    "    .appName(\"dataframe-array\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.default.parallelism\", 8)\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", NUM_CORES * NUM_PARTITIONS)\n",
    "/*\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", NUM_CORES * NUM_PARTITIONS)\n",
    "spark.conf.set(\"spark.default.parallelism\", NUM_CORES * NUM_PARTITIONS)\n",
    "spark.conf.set(\"spark.driver.memory\", \"6g\")\n",
    "spark.conf.set(\"spark.executor.memory\", \"2g\")\n",
    "spark.conf.set(\"spark.master\", \"spark://masa:7077\")\n",
    "*/\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(spark.serializer,org.apache.spark.serializer.KryoSerializer)\n",
      "(spark.driver.host,192.168.1.116)\n",
      "(spark.eventLog.enabled,true)\n",
      "(spark.driver.port,34465)\n",
      "(spark.hadoop.validateOutputSpecs,True)\n",
      "(spark.repl.class.uri,spark://192.168.1.116:34465/classes)\n",
      "(spark.jars,file:/home/oonisim/.local/share/jupyter/kernels/apache_toree_scala/lib/toree-assembly-0.3.0-incubating.jar)\n",
      "(spark.repl.class.outputDir,/tmp/spark-8747b854-8bc9-4b2b-a0d3-59be4e5e8749/repl-ccfa7214-cdcf-436b-a0f8-b9bb6a095c57)\n",
      "(spark.app.name,flight)\n",
      "(spark.driver.memory,2g)\n",
      "(spark.executor.instances,2)\n",
      "(spark.history.fs.logdirectory,hdfs://localhost:8020/logs_spark)\n",
      "(spark.default.parallelism,8)\n",
      "(spark.executor.id,driver)\n",
      "(spark.submit.deployMode,client)\n",
      "(spark.master,local)\n",
      "(spark.executor.memory,4g)\n",
      "(spark.eventLog.dir,hdfs://localhost:8020/logs_spark)\n",
      "(spark.executor.cores,4)\n",
      "(spark.app.id,local-1575786019867)\n",
      "(spark.sql.shuffle.partitions,4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "configMap: Unit = ()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val configMap = spark.conf.getAll.foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = false)\n",
      " |-- today: date (nullable = false)\n",
      " |-- now: timestamp (nullable = false)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dateDF = [id: bigint, today: date ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[id: bigint, today: date ... 1 more field]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dateDF = spark.range(10)\n",
    "  .withColumn(\"today\", current_date())\n",
    "  .withColumn(\"now\", current_timestamp())\n",
    "dateDF.createOrReplaceTempView(\"dateTable\")\n",
    "\n",
    "dateDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+-------------------+\n",
      "|complex                                     |InvoiceDate        |\n",
      "+--------------------------------------------+-------------------+\n",
      "|[WHITE HANGING HEART T-LIGHT HOLDER, 536365]|2010-12-01 08:26:00|\n",
      "|[WHITE METAL LANTERN, 536365]               |2010-12-01 08:26:00|\n",
      "|[CREAM CUPID HEARTS COAT HANGER, 536365]    |2010-12-01 08:26:00|\n",
      "+--------------------------------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "complexDF = [complex: struct<Description: string, InvoiceNo: string>, InvoiceDate: timestamp]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[complex: struct<Description: string, InvoiceNo: string>, InvoiceDate: timestamp]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val complexDF = df.selectExpr(\"(Description, InvoiceNo) as complex\", \"InvoiceDate\")\n",
    "complexDF.show(3, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+\n",
      "|Description                       |\n",
      "+----------------------------------+\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER|\n",
      "|WHITE METAL LANTERN               |\n",
      "|CREAM CUPID HEARTS COAT HANGER    |\n",
      "+----------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complexDF.select(\"complex.Description\").show(3, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|complex.InvoiceNo|\n",
      "+-----------------+\n",
      "|           536365|\n",
      "|           536365|\n",
      "|           536365|\n",
      "+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complexDF.select(col(\"complex\").getField(\"InvoiceNo\")).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split a column into array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+---------------+--------------+\n",
      "|array_col                               |size(array_col)|contains_WHITE|\n",
      "+----------------------------------------+---------------+--------------+\n",
      "|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|5              |true          |\n",
      "|[WHITE, METAL, LANTERN]                 |3              |true          |\n",
      "|[CREAM, CUPID, HEARTS, COAT, HANGER]    |5              |false         |\n",
      "+----------------------------------------+---------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "arrayDF = [array_col: array<string>, size(array_col): int ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[array_col: array<string>, size(array_col): int ... 1 more field]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val arrayDF = df.select(split(col(\"Description\"), \" \").alias(\"array_col\"))\n",
    ".select(\n",
    "    col(\"array_col\"),\n",
    "    size(col(\"array_col\"))\n",
    ")\n",
    ".withColumn(\n",
    "    \"contains_WHITE\",\n",
    "    array_contains(col(\"array_col\"), \"WHITE\")\n",
    ")\n",
    "arrayDF.show(3, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Array elements into rows\n",
    "Create a row for each array value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+\n",
      "|array_col                               |\n",
      "+----------------------------------------+\n",
      "|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|\n",
      "+----------------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "arrayRowDF = [array_col: array<string>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[array_col: array<string>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val arrayRowDF = arrayDF.selectExpr(\n",
    "    \"array_col\"\n",
    ")\n",
    ".limit(1)\n",
    "\n",
    "arrayRowDF.show(1, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+--------+\n",
      "|array_col                               |exploded|\n",
      "+----------------------------------------+--------+\n",
      "|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|WHITE   |\n",
      "|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|HANGING |\n",
      "|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|HEART   |\n",
      "|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|T-LIGHT |\n",
      "|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|HOLDER  |\n",
      "+----------------------------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// For each value in [WHITE, HANGING, HEART, T-LIGHT, HOLDER], a row is created\n",
    "arrayRowDF\n",
    "  .withColumn(\"exploded\", explode(col(\"array_col\")))\n",
    "  .selectExpr(\n",
    "      \"array_col\", \"exploded\"\n",
    "  )\n",
    "  .show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
