{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 25 - Preprocessing - Text Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types will be printed.\n"
     ]
    }
   ],
   "source": [
    "%ShowTypes on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.linalg._\n",
    "import org.apache.spark.mllib.linalg.distributed._\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.sql.Row\n",
    "\n",
    "import org.apache.spark.sql.expressions._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.SaveMode\n",
    "import org.apache.spark.sql.DataFrame\n",
    "\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.classification._\n",
    "import org.apache.spark.ml.feature._\n",
    "import org.apache.spark.ml.linalg.Vector\n",
    "\n",
    "import spark.implicits._\n",
    "\n",
    "import java.time.temporal.ChronoUnit\n",
    "import java.time.{Period, LocalDate, Instant}\n",
    "import java.sql.Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- To left align the HTML components in Markdown -->\n",
       "<style>\n",
       "table {float:left}\n",
       "</style>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%html\n",
    "<!-- To left align the HTML components in Markdown -->\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark parition control based on core availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NUM_CORES: Int = 4\n",
       "NUM_PARTITIONS: Int = 4\n",
       "spark: org.apache.spark.sql.SparkSession = <lazy>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = <lazy>\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val NUM_CORES = 4\n",
    "val NUM_PARTITIONS = 4\n",
    "\n",
    "lazy val spark: SparkSession = SparkSession.builder()\n",
    "    .appName(\"mllib-cross-validation\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.default.parallelism\", NUM_CORES * NUM_PARTITIONS)\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", NUM_CORES * NUM_PARTITIONS)\n",
    "/*\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", NUM_CORES * NUM_PARTITIONS)\n",
    "spark.conf.set(\"spark.default.parallelism\", NUM_CORES * NUM_PARTITIONS)\n",
    "spark.conf.set(\"spark.driver.memory\", \"6g\")\n",
    "spark.conf.set(\"spark.executor.memory\", \"2g\")\n",
    "spark.conf.set(\"spark.master\", \"spark://masa:7077\")\n",
    "*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(spark.serializer,org.apache.spark.serializer.KryoSerializer)\n",
      "(spark.driver.host,10.186.87.0)\n",
      "(spark.eventLog.enabled,true)\n",
      "(spark.driver.port,45915)\n",
      "(spark.hadoop.validateOutputSpecs,True)\n",
      "(spark.repl.class.uri,spark://10.186.87.0:45915/classes)\n",
      "(spark.jars,file:/home/oonisim/.local/share/jupyter/kernels/apache_toree_scala/lib/toree-assembly-0.3.0-incubating.jar)\n",
      "(spark.repl.class.outputDir,/tmp/spark-16dc876b-3e5b-4038-97a6-36eff616d985/repl-48be94f1-8be2-408f-b45b-117a9f280ab6)\n",
      "(spark.app.name,mllib-cross-validation)\n",
      "(spark.driver.memory,3g)\n",
      "(spark.executor.instances,2)\n",
      "(spark.history.fs.logdirectory,hdfs://oonisim:8020/logs_spark)\n",
      "(spark.default.parallelism,16)\n",
      "(spark.executor.id,driver)\n",
      "(spark.submit.deployMode,client)\n",
      "(spark.master,yarn)\n",
      "(spark.ui.filters,org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter)\n",
      "(spark.executor.memory,4g)\n",
      "(spark.eventLog.dir,hdfs://oonisim:8020/logs_spark)\n",
      "(spark.executor.cores,4)\n",
      "(spark.driver.appUIAddress,http://10.186.87.0:4040)\n",
      "(spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS,oonisim)\n",
      "(spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES,http://oonisim:8088/proxy/application_1576492736995_0002)\n",
      "(spark.app.id,application_1576492736995_0002)\n",
      "(spark.sql.shuffle.partitions,16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "configMap: Unit = ()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val configMap = spark.conf.getAll.foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PROTOCOL: String = file://\n",
       "DATA_DIR: String = /home/oonisim/home/repositories/git/oonisim/spark-programs/Dataframe/data\n",
       "RESULT_DIR: String = .\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RESULT_DIR: String = .\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val PROTOCOL=\"file://\"\n",
    "val DATA_DIR=\"/home/oonisim/home/repositories/git/oonisim/spark-programs/Dataframe/data\"\n",
    "val RESULT_DIR=\".\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sales: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [InvoiceNo: string, StockCode: string ... 6 more fields]\n",
       "fakeIntDF: org.apache.spark.sql.DataFrame = [int1: int, int2: int ... 1 more field]\n",
       "simpleDF: org.apache.spark.sql.DataFrame = [color: string, lab: string ... 2 more fields]\n",
       "scaleDF: org.apache.spark.sql.DataFrame = [id: int, features: vector]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "scaleDF: org.apache.spark.sql.DataFrame = [id: int, features: vector]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sales = spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .load(PROTOCOL + DATA_DIR + \"/retail-data/by-day/*.csv\")\n",
    "  .coalesce(5)\n",
    "  .where(\"Description IS NOT NULL\")\n",
    "val fakeIntDF = spark.read.parquet(PROTOCOL + DATA_DIR + \"/simple-ml-integers\")\n",
    "var simpleDF = spark.read.json(PROTOCOL + DATA_DIR + \"/simple-ml\")\n",
    "val scaleDF = spark.read.parquet(PROTOCOL + DATA_DIR + \"/simple-ml-scaling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   580538|    23084|  RABBIT NIGHT LIGHT|      48|2011-12-05 08:38:00|     1.79|   14075.0|United Kingdom|\n",
      "|   580538|    23077| DOUGHNUT LIP GLOSS |      20|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n",
      "|   580538|    22906|12 MESSAGE CARDS ...|      24|2011-12-05 08:38:00|     1.65|   14075.0|United Kingdom|\n",
      "|   580538|    21914|BLUE HARMONICA IN...|      24|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n",
      "|   580538|    22467|   GUMBALL COAT RACK|       6|2011-12-05 08:38:00|     2.55|   14075.0|United Kingdom|\n",
      "|   580538|    21544|SKULLS  WATER TRA...|      48|2011-12-05 08:38:00|     0.85|   14075.0|United Kingdom|\n",
      "|   580538|    23126|FELTCRAFT GIRL AM...|       8|2011-12-05 08:38:00|     4.95|   14075.0|United Kingdom|\n",
      "|   580538|    21833|CAMOUFLAGE LED TORCH|      24|2011-12-05 08:38:00|     1.69|   14075.0|United Kingdom|\n",
      "|   580539|    21479|WHITE SKULL HOT W...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "|   580539|   84030E|ENGLISH ROSE HOT ...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "|   580539|    23355|HOT WATER BOTTLE ...|       4|2011-12-05 08:39:00|     4.95|   18180.0|United Kingdom|\n",
      "|   580539|    22111|SCOTTIE DOG HOT W...|       3|2011-12-05 08:39:00|     4.95|   18180.0|United Kingdom|\n",
      "|   580539|    21115|ROSE CARAVAN DOOR...|       8|2011-12-05 08:39:00|     1.95|   18180.0|United Kingdom|\n",
      "|   580539|    21411|GINGHAM HEART  DO...|       8|2011-12-05 08:39:00|     1.95|   18180.0|United Kingdom|\n",
      "|   580539|    23235|STORAGE TIN VINTA...|      12|2011-12-05 08:39:00|     1.25|   18180.0|United Kingdom|\n",
      "|   580539|    23239|SET OF 4 KNICK KN...|       6|2011-12-05 08:39:00|     1.65|   18180.0|United Kingdom|\n",
      "|   580539|    22197|      POPCORN HOLDER|      36|2011-12-05 08:39:00|     0.85|   18180.0|United Kingdom|\n",
      "|   580539|    22693|GROW A FLYTRAP OR...|      24|2011-12-05 08:39:00|     1.25|   18180.0|United Kingdom|\n",
      "|   580539|    22372|AIRLINE BAG VINTA...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "|   580539|    22375|AIRLINE BAG VINTA...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales.cache()\n",
    "sales.printSchema\n",
    "sales.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer: org.apache.spark.ml.feature.Tokenizer = tok_b443228f5ce9\n",
       "tokenDF: org.apache.spark.sql.DataFrame = [Description: string, Tokens: array<string>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenDF: org.apache.spark.sql.DataFrame = [Description: string, Tokens: array<string>]\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tokenizer = new Tokenizer()\n",
    "    .setInputCol(\"Description\")\n",
    "    .setOutputCol(\"Tokens\")\n",
    "val tokenDF = tokenizer.transform(sales)\n",
    "    .select(\"Description\", \"Tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+-------------------------------------+\n",
      "|Description                    |Tokens                               |\n",
      "+-------------------------------+-------------------------------------+\n",
      "|RABBIT NIGHT LIGHT             |[rabbit, night, light]               |\n",
      "|DOUGHNUT LIP GLOSS             |[doughnut, lip, gloss]               |\n",
      "|12 MESSAGE CARDS WITH ENVELOPES|[12, message, cards, with, envelopes]|\n",
      "|BLUE HARMONICA IN BOX          |[blue, harmonica, in, box]           |\n",
      "|GUMBALL COAT RACK              |[gumball, coat, rack]                |\n",
      "+-------------------------------+-------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenDF.show(5, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+---------------------------------------------------------------------------------------+\n",
      "|Tokens                                    |ngram_9dfb0a4f628d__output                                                             |\n",
      "+------------------------------------------+---------------------------------------------------------------------------------------+\n",
      "|[rabbit, night, light]                    |[rabbit night light]                                                                   |\n",
      "|[doughnut, lip, gloss]                    |[doughnut lip gloss]                                                                   |\n",
      "|[12, message, cards, with, envelopes]     |[12 message cards, message cards with, cards with envelopes]                           |\n",
      "|[blue, harmonica, in, box]                |[blue harmonica in, harmonica in box]                                                  |\n",
      "|[gumball, coat, rack]                     |[gumball coat rack]                                                                    |\n",
      "|[skulls, , water, transfer, tattoos]      |[skulls  water,  water transfer, water transfer tattoos]                               |\n",
      "|[feltcraft, girl, amelie, kit]            |[feltcraft girl amelie, girl amelie kit]                                               |\n",
      "|[camouflage, led, torch]                  |[camouflage led torch]                                                                 |\n",
      "|[white, skull, hot, water, bottle]        |[white skull hot, skull hot water, hot water bottle]                                   |\n",
      "|[english, rose, hot, water, bottle]       |[english rose hot, rose hot water, hot water bottle]                                   |\n",
      "|[hot, water, bottle, keep, calm]          |[hot water bottle, water bottle keep, bottle keep calm]                                |\n",
      "|[scottie, dog, hot, water, bottle]        |[scottie dog hot, dog hot water, hot water bottle]                                     |\n",
      "|[rose, caravan, doorstop]                 |[rose caravan doorstop]                                                                |\n",
      "|[gingham, heart, , doorstop, red]         |[gingham heart , heart  doorstop,  doorstop red]                                       |\n",
      "|[storage, tin, vintage, leaf]             |[storage tin vintage, tin vintage leaf]                                                |\n",
      "|[set, of, 4, knick, knack, tins, poppies] |[set of 4, of 4 knick, 4 knick knack, knick knack tins, knack tins poppies]            |\n",
      "|[popcorn, holder]                         |[]                                                                                     |\n",
      "|[grow, a, flytrap, or, sunflower, in, tin]|[grow a flytrap, a flytrap or, flytrap or sunflower, or sunflower in, sunflower in tin]|\n",
      "|[airline, bag, vintage, world, champion]  |[airline bag vintage, bag vintage world, vintage world champion]                       |\n",
      "|[airline, bag, vintage, jet, set, brown]  |[airline bag vintage, bag vintage jet, vintage jet set, jet set brown]                 |\n",
      "+------------------------------------------+---------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trigram: org.apache.spark.ml.feature.NGram = ngram_9dfb0a4f628d\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "trigram: org.apache.spark.ml.feature.NGram = ngram_9dfb0a4f628d\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trigram = new NGram().setInputCol(\"Tokens\").setN(3)\n",
    "trigram.transform(tokenDF.select(\"Tokens\")).show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency of word appearance\n",
    "* Term: Word\n",
    "* Document: in which term appears\n",
    "* Vocabrary: collection of terms\n",
    "\n",
    "## Term Freququency (TF)\n",
    "Number of times a term appeared in all documents\n",
    "\n",
    "## Document Frequencey (DF)\n",
    "\n",
    "Number of documents in which a term appeared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+----------------------------------------------------------------+\n",
      "|Tokens                                    |Frequencies                                                     |\n",
      "+------------------------------------------+----------------------------------------------------------------+\n",
      "|[rabbit, night, light]                    |(2374,[149,185,212],[1.0,1.0,1.0])                              |\n",
      "|[doughnut, lip, gloss]                    |(2374,[462,463,491],[1.0,1.0,1.0])                              |\n",
      "|[12, message, cards, with, envelopes]     |(2374,[35,41,166,782,942],[1.0,1.0,1.0,1.0,1.0])                |\n",
      "|[blue, harmonica, in, box]                |(2374,[10,16,36,352],[1.0,1.0,1.0,1.0])                         |\n",
      "|[gumball, coat, rack]                     |(2374,[228,280,407],[1.0,1.0,1.0])                              |\n",
      "|[skulls, , water, transfer, tattoos]      |(2374,[11,40,133,1169,1170],[1.0,1.0,1.0,1.0,1.0])              |\n",
      "|[feltcraft, girl, amelie, kit]            |(2374,[60,64,69,879],[1.0,1.0,1.0,1.0])                         |\n",
      "|[camouflage, led, torch]                  |(2374,[263,1006,1182],[1.0,1.0,1.0])                            |\n",
      "|[white, skull, hot, water, bottle]        |(2374,[15,34,39,40,118],[1.0,1.0,1.0,1.0,1.0])                  |\n",
      "|[english, rose, hot, water, bottle]       |(2374,[34,39,40,46,169],[1.0,1.0,1.0,1.0,1.0])                  |\n",
      "|[hot, water, bottle, keep, calm]          |(2374,[34,39,40,147,148],[1.0,1.0,1.0,1.0,1.0])                 |\n",
      "|[scottie, dog, hot, water, bottle]        |(2374,[34,39,40,146,386],[1.0,1.0,1.0,1.0,1.0])                 |\n",
      "|[rose, caravan, doorstop]                 |(2374,[46,297,684],[1.0,1.0,1.0])                               |\n",
      "|[gingham, heart, , doorstop, red]         |(2374,[3,4,11,143,297],[1.0,1.0,1.0,1.0,1.0])                   |\n",
      "|[storage, tin, vintage, leaf]             |(2374,[6,45,109,162],[1.0,1.0,1.0,1.0])                         |\n",
      "|[set, of, 4, knick, knack, tins, poppies] |(2374,[0,1,49,70,365,366,787],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])    |\n",
      "|[popcorn, holder]                         |(2374,[21,296],[1.0,1.0])                                       |\n",
      "|[grow, a, flytrap, or, sunflower, in, tin]|(2374,[36,45,378,510,622,832,872],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|[airline, bag, vintage, world, champion]  |(2374,[2,6,328,548,1234],[1.0,1.0,1.0,1.0,1.0])                 |\n",
      "|[airline, bag, vintage, jet, set, brown]  |(2374,[0,2,6,328,405,620],[1.0,1.0,1.0,1.0,1.0,1.0])            |\n",
      "+------------------------------------------+----------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cv: org.apache.spark.ml.feature.CountVectorizer = cntVec_94969b77d336\n",
       "fittedCV: org.apache.spark.ml.feature.CountVectorizerModel = cntVec_94969b77d336\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fittedCV: org.apache.spark.ml.feature.CountVectorizerModel = cntVec_94969b77d336\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cv = new CountVectorizer()\n",
    "  .setInputCol(\"Tokens\")\n",
    "  .setOutputCol(\"Frequencies\")\n",
    "  .setVocabSize(5000)\n",
    "  .setMinTF(1)\n",
    "  .setMinDF(2)\n",
    "val fittedCV = cv.fit(tokenDF.select(\"Tokens\"))\n",
    "fittedCV.transform(tokenDF.select(\"Tokens\")).show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
