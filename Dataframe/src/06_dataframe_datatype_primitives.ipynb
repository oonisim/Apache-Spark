{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 - Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.linalg._\n",
    "import org.apache.spark.mllib.linalg.distributed._\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.sql.Row\n",
    "\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.SaveMode\n",
    "import org.apache.spark.sql.DataFrame\n",
    "\n",
    "import java.time.temporal.ChronoUnit\n",
    "import java.time.{Period, LocalDate, Instant}\n",
    "import java.sql.Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark parition control based on core availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NUM_CORES = 2\n",
       "NUM_PARTITIONS = 2\n",
       "spark = <lazy>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<lazy>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val NUM_CORES = 2\n",
    "val NUM_PARTITIONS = 2\n",
    "\n",
    "lazy val spark: SparkSession = SparkSession.builder()\n",
    "    .master(\"local\")\n",
    "    .appName(\"flight\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.default.parallelism\", 8)\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", NUM_CORES * NUM_PARTITIONS)\n",
    "/*\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", NUM_CORES * NUM_PARTITIONS)\n",
    "spark.conf.set(\"spark.default.parallelism\", NUM_CORES * NUM_PARTITIONS)\n",
    "spark.conf.set(\"spark.driver.memory\", \"6g\")\n",
    "spark.conf.set(\"spark.executor.memory\", \"2g\")\n",
    "spark.conf.set(\"spark.master\", \"spark://masa:7077\")\n",
    "*/\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(spark.serializer,org.apache.spark.serializer.KryoSerializer)\n",
      "(spark.driver.host,192.168.1.116)\n",
      "(spark.eventLog.enabled,true)\n",
      "(spark.driver.port,34465)\n",
      "(spark.hadoop.validateOutputSpecs,True)\n",
      "(spark.repl.class.uri,spark://192.168.1.116:34465/classes)\n",
      "(spark.jars,file:/home/oonisim/.local/share/jupyter/kernels/apache_toree_scala/lib/toree-assembly-0.3.0-incubating.jar)\n",
      "(spark.repl.class.outputDir,/tmp/spark-8747b854-8bc9-4b2b-a0d3-59be4e5e8749/repl-ccfa7214-cdcf-436b-a0f8-b9bb6a095c57)\n",
      "(spark.app.name,flight)\n",
      "(spark.driver.memory,2g)\n",
      "(spark.executor.instances,2)\n",
      "(spark.history.fs.logdirectory,hdfs://localhost:8020/logs_spark)\n",
      "(spark.default.parallelism,8)\n",
      "(spark.executor.id,driver)\n",
      "(spark.submit.deployMode,client)\n",
      "(spark.master,local)\n",
      "(spark.executor.memory,4g)\n",
      "(spark.eventLog.dir,hdfs://localhost:8020/logs_spark)\n",
      "(spark.executor.cores,4)\n",
      "(spark.app.id,local-1575786019867)\n",
      "(spark.sql.shuffle.partitions,4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "configMap: Unit = ()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val configMap = spark.conf.getAll.foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elapsed time profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timing = \n",
       "times = ListBuffer()\n",
       "timed = > Nothing) => Nothing = <function2>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "clear: ()Unit\n",
       "average: ()Long\n",
       "_timed: [T](label: String, code: => T)T\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "> Nothing) => Nothing = <function2>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.collection.mutable.ListBuffer\n",
    "\n",
    "val timing = new StringBuffer\n",
    "val times = new ListBuffer[Long]()\n",
    "\n",
    "def clear(): Unit = {\n",
    "    timing.setLength(0)\n",
    "    times.clear\n",
    "}\n",
    "def average(): Long = {\n",
    "    times.reduce(_+_) / times.length\n",
    "}\n",
    "\n",
    "/**\n",
    "@param label Description about the run\n",
    "@code code to execute\n",
    "@return execution\n",
    "*/\n",
    "def _timed[T](label: String, code: => T): T = {\n",
    "    val start = System.currentTimeMillis()\n",
    "    val result = code\n",
    "    val stop = System.currentTimeMillis()\n",
    "    timing.append(s\"Processing $label took ${stop - start} ms.\\n\")\n",
    "    times.append(stop - start)\n",
    "    result\n",
    "}\n",
    "\n",
    "val timed = _timed _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<console>:54: error: missing argument list for method _timed\n",
       "Unapplied methods are only converted to functions when a function type is expected.\n",
       "You can make this conversion explicit by writing `_timed _` or `_timed(_,_)` instead of `_timed`.\n",
       "       _timed\n",
       "       ^\n",
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// To flush out error: missing argument list for method timed\n",
    "println(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "save: (df: org.apache.spark.sql.DataFrame)Unit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save(df: DataFrame) = {\n",
    "    df.coalesce(1)\n",
    "    .write\n",
    "    .format(\"csv\")\n",
    "    .mode(SaveMode.Overwrite)\n",
    "    .option(\"header\", \"true\")\n",
    "    .save(RESULT_DIR)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df = [InvoiceNo: string, StockCode: string ... 6 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[InvoiceNo: string, StockCode: string ... 6 more fields]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .load(\"../data/retail-data/by-day/2010-12-01.csv\")\n",
    "df.printSchema()\n",
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|   17850.0|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literal\n",
    "\n",
    "SQL can select literals:\n",
    "```\n",
    "SELECT CAST(5 AS int), \"five\", 5.0 FROM DUAL\n",
    "```\n",
    "\n",
    "SparkSQL lit function provides the equivalent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n",
      "|  5|five|5.0|\n",
      "+---+----+---+\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "+---+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(lit(5), lit(\"five\"), lit(5.0))\n",
    "    .limit(5)\n",
    "    .show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+----------+---------+--------+\n",
      "|monotonically_increasing_id()|customerId|UnitPrice|Quantity|\n",
      "+-----------------------------+----------+---------+--------+\n",
      "|                            0|   17850.0|     2.55|       6|\n",
      "|                            1|   17850.0|     3.39|       6|\n",
      "|                            2|   17850.0|     2.75|       8|\n",
      "|                            3|   17850.0|     3.39|       6|\n",
      "|                            4|   17850.0|     3.39|       6|\n",
      "+-----------------------------+----------+---------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "        monotonically_increasing_id(),\n",
    "        col(\"customerId\"),\n",
    "        col(\"UnitPrice\"),\n",
    "        col(\"Quantity\")\n",
    "    )\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CustomerId|      realQuantity|\n",
      "+----------+------------------+\n",
      "|   17850.0|239.08999999999997|\n",
      "|   17850.0|          418.7156|\n",
      "+----------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "/*\n",
    "SELECT \n",
    "    customerId, \n",
    "    (POWER((Quantity * UnitPrice), 2.0) + 5) as realQuantity\n",
    "FROM dfTable\n",
    "*/\n",
    "df.selectExpr(\n",
    "  \"CustomerId\",\n",
    "  \"(POWER((Quantity * UnitPrice), 2.0) + 5) as realQuantity\"\n",
    ").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+--------+-----+\n",
      "|UnitPrice|rounded|Quantity|total|\n",
      "+---------+-------+--------+-----+\n",
      "|     2.55|    2.6|       6| 15.3|\n",
      "|     3.39|    3.4|       6|20.34|\n",
      "|     2.75|    2.8|       8| 22.0|\n",
      "|     3.39|    3.4|       6|20.34|\n",
      "|     3.39|    3.4|       6|20.34|\n",
      "+---------+-------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    col(\"UnitPrice\"),\n",
    "    round(\n",
    "        col(\"UnitPrice\"), \n",
    "        1\n",
    "    ).alias(\"rounded\"), \n",
    "    col(\"Quantity\"),\n",
    "    round(\n",
    "        (col(\"UnitPrice\") * col(\"Quantity\")),\n",
    "        5\n",
    "    ).alias(\"total\")\n",
    ")\n",
    ".show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|         UnitPrice|          Quantity|\n",
      "+-------+------------------+------------------+\n",
      "|  count|              3108|              3108|\n",
      "|   mean| 4.151946589446603| 8.627413127413128|\n",
      "| stddev|15.638659854603892|26.371821677029203|\n",
      "|    min|               0.0|               -24|\n",
      "|    max|            607.49|               600|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\n",
    "        \"UnitPrice\",\n",
    "        \"Quantity\"\n",
    "    )\n",
    "    .describe()\n",
    "    .show(5, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+--------------+----------------+\n",
      "|stddev_samp(UnitPrice)|max(UnitPrice)|count(UnitPrice)|\n",
      "+----------------------+--------------+----------------+\n",
      "|    15.638659854603892|        607.49|            3108|\n",
      "+----------------------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df\n",
    "    .select(\n",
    "        stddev(col(\"UnitPrice\")),\n",
    "        max(col(\"UnitPrice\")),\n",
    "        count(col(\"UnitPrice\"))\n",
    "    )\n",
    "    .show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04112314436835552"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stat.corr(\"UnitPrice\", \"Quantity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String\n",
    "* padding\n",
    "* lower/upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+-----------------------------------+\n",
      "|upper(Description)                 |leftpadded                         |\n",
      "+-----------------------------------+-----------------------------------+\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER | white hanging heart t-light holder|\n",
      "|WHITE METAL LANTERN                |                white metal lantern|\n",
      "|CREAM CUPID HEARTS COAT HANGER     |     cream cupid hearts coat hanger|\n",
      "|KNITTED UNION FLAG HOT WATER BOTTLE|knitted union flag hot water bottle|\n",
      "|RED WOOLLY HOTTIE WHITE HEART.     |     red woolly hottie white heart.|\n",
      "+-----------------------------------+-----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df\n",
    "    .select(\n",
    "        upper(col(\"Description\")),\n",
    "        //--------------------------------------------------------------------------------\n",
    "        // lpad(str, len, pad) - left-padded with pad to a length of len. \n",
    "        // If str is longer than len, the return value is shortened to len characters.\n",
    "        //--------------------------------------------------------------------------------\n",
    "        lpad(\n",
    "            lower(col(\"Description\")),\n",
    "            35,\n",
    "            \" \"\n",
    "        ).alias(\"leftpadded\")\n",
    "    )\n",
    "    .show(5, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|     regexp_replaced|         Description|\n",
      "+--------------------+--------------------+\n",
      "|           ReplacedR|WHITE HANGING HEA...|\n",
      "|          ReplacedRN| WHITE METAL LANTERN|\n",
      "|CREAM CUPID HEART...|CREAM CUPID HEART...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "  regexp_replace(col(\"Description\"), \"W(.*)E| METAL\", \"Replaced\").alias(\"regexp_replaced\"),\n",
    "  col(\"Description\")).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace maching characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+--------------------+\n",
      "|translate(Description, LEHT, leht)|         Description|\n",
      "+----------------------------------+--------------------+\n",
      "|              WhIte hANGING heA...|WHITE HANGING HEA...|\n",
      "|               WhIte MetAl lANteRN| WHITE METAL LANTERN|\n",
      "+----------------------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(translate(col(\"Description\"), \"LEHT\", \"leht\"), col(\"Description\"))\n",
    "  .show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
