{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 03\n",
    "Find the greatest number of countries a passenger has been in without being in the UK. For example, if the countries a passenger was in were: UK -> FR -> US -> CN -> UK -> DE -> UK, the correct answer would be 3 countries.\n",
    "\n",
    "## Assumptions\n",
    "1. Data is clearned and not errorneous\n",
    "2. Timezone consideration is not required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.SaveMode\n",
    "import org.apache.spark.sql.functions._\n",
    "import java.time.temporal.ChronoUnit\n",
    "import java.time.{Period, LocalDate, Instant}\n",
    "import java.sql.Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark parition control based on core availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NUM_CORES = 4\n",
       "NUM_PARTITIONS = 3\n",
       "spark = <lazy>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<lazy>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val NUM_CORES = 4\n",
    "val NUM_PARTITIONS = 3\n",
    "\n",
    "lazy val spark: SparkSession = SparkSession.builder()\n",
    "    .master(\"local\")\n",
    "    .appName(\"flight\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", NUM_CORES * NUM_PARTITIONS)\n",
    "spark.conf.set(\"spark.default.parallelism\", NUM_CORES * NUM_PARTITIONS)\n",
    "\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elapsed time profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timing = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "timed: [T](label: String, code: => T)T\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val timing = new StringBuffer\n",
    "def timed[T](label: String, code: => T): T = {\n",
    "    val start = System.currentTimeMillis()\n",
    "    val result = code\n",
    "    val stop = System.currentTimeMillis()\n",
    "    timing.append(s\"Processing $label took ${stop - start} ms.\\n\")\n",
    "    result\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<console>:46: error: missing argument list for method timed\n",
       "Unapplied methods are only converted to functions when a function type is expected.\n",
       "You can make this conversion explicit by writing `timed _` or `timed(_,_)` instead of `timed`.\n",
       "       timed\n",
       "       ^\n",
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// To flush out error: missing argument list for method timed\n",
    "println(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FLIGHTDATA_CSV_PATH = ../resources/flightData.csv\n",
       "PASSENGER_CSV_PATH = ../resources/passengers.csv\n",
       "RESULT_DIR = results/longestRun\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "results/longestRun"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val FLIGHTDATA_CSV_PATH = \"../resources/flightData.csv\"\n",
    "val PASSENGER_CSV_PATH = \"../resources/passengers.csv\"\n",
    "val RESULT_DIR = \"results/longestRun\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BASE_LOCALDATE = 2017-01-01\n",
       "udf_months_between = UserDefinedFunction(<function1>,ShortType,Some(List(TimestampType)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "get_months_between: (to: java.sql.Timestamp)Short\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function1>,ShortType,Some(List(TimestampType)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//val BASE_TIMESTAMP = java.sql.Timestamp.valueOf(\"2017-01-01 00:00:00.0\")\n",
    "val BASE_LOCALDATE = LocalDate.parse(\"2017-01-01\").withDayOfMonth(1)\n",
    "\n",
    "def get_months_between(to: Timestamp): Short = {\n",
    "    val monthsBetween = ChronoUnit.MONTHS.between(\n",
    "        BASE_LOCALDATE,\n",
    "        to.toLocalDateTime().toLocalDate().withDayOfMonth(1)\n",
    "    )\n",
    "    monthsBetween.toShort\n",
    "}\n",
    "val udf_months_between = udf((t:Timestamp) => get_months_between(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passengerId: integer (nullable = true)\n",
      " |-- flightId: integer (nullable = true)\n",
      " |-- from: string (nullable = true)\n",
      " |-- to: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- direction: integer (nullable = false)\n",
      " |-- count: integer (nullable = false)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "flightData = [passengerId: int, flightId: int ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, flightId: int ... 5 more fields]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Transformations, no action yet\n",
    "val flightData = spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"delimiter\", \",\")\n",
    "    .option(\"dateFormat\", \"yyyy-MM-dd\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(\"../resources/flightData.csv\")\n",
    "    .withColumn(\n",
    "        \"direction\", \n",
    "        when(lower(col(\"from\")) === \"uk\", 1)\n",
    "        .when(lower(col(\"to\"))   === \"uk\", -1)\n",
    "        .otherwise(0)\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"count\", lit(1)\n",
    "    )\n",
    "    .orderBy(asc(\"passengerId\"), asc(\"date\"))\n",
    "\n",
    "flightData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flightData.createOrReplaceTempView(\"flightData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//flightData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "querySequencedRun = \n",
       "sequencedRun = [passengerId: int, flightId: int ... 6 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\n",
       "SELECT\n",
       "    f.*,\n",
       "    ROW_NUMBER() OVER (PARTITION BY passengerId ORDER BY passengerId, date) as seq\n",
       "FROM\n",
       "    flightData f\n",
       "ORDER BY\n",
       "    passengerId, date\n",
       "\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, flightId: int ... 6 more fields]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val querySequencedRun = \"\"\"\n",
    "SELECT \n",
    "    f.*,\n",
    "    ROW_NUMBER() OVER (PARTITION BY passengerId ORDER BY passengerId, date) as seq \n",
    "FROM\n",
    "    flightData f\n",
    "ORDER BY \n",
    "    passengerId, date\n",
    "\"\"\"\n",
    "\n",
    "val sequencedRun = spark.sql(querySequencedRun)\n",
    "sequencedRun.createOrReplaceTempView(\"sequencedRun\")\n",
    "\n",
    "/* For debug only\n",
    "sequencedRun\n",
    "    .filter(col(\"passengerId\") === 53)\n",
    "    .show()\n",
    "*/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longest run per passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "queryLongestRun = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\n",
       "WITH\n",
       "    closedRun AS (\n",
       "        SELECT\n",
       "            passengerId,\n",
       "            from, to,\n",
       "            direction,\n",
       "            seq,\n",
       "            --------------------------------------------------------------------------------\n",
       "            -- For a departure flight, take the the return flight, if there is, seq num\n",
       "            --------------------------------------------------------------------------------\n",
       "            CASE\n",
       "                WHEN direction == 1\n",
       "                THEN lead(seq) OVER (PARTITION BY passengerId ORDER BY seq)\n",
       "            END AS return,\n",
       "            --------------------------------------------------------------------------------\n",
       "            -- For a departure flight, count the visiting countries, if returned.\n",
       "            --------------------------...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val queryLongestRun = \"\"\"\n",
    "WITH \n",
    "    closedRun AS (\n",
    "        SELECT \n",
    "            passengerId, \n",
    "            from, to, \n",
    "            direction, \n",
    "            seq,\n",
    "            -------------------------------------------------------------------------------- \n",
    "            -- For a departure flight, take the the return flight, if there is, seq num\n",
    "            -------------------------------------------------------------------------------- \n",
    "            CASE \n",
    "                WHEN direction == 1\n",
    "                THEN lead(seq) OVER (PARTITION BY passengerId ORDER BY seq)\n",
    "            END AS return,\n",
    "            -------------------------------------------------------------------------------- \n",
    "            -- For a departure flight, count the visiting countries, if returned.\n",
    "            -------------------------------------------------------------------------------- \n",
    "            CASE \n",
    "                WHEN direction == 1\n",
    "                THEN lead(seq) OVER (PARTITION BY passengerId ORDER BY seq) - seq\n",
    "            END AS countries\n",
    "        FROM sequencedRun s\n",
    "        WHERE \n",
    "            direction != 0\n",
    "            AND EXISTS (  \n",
    "                SELECT passengerId\n",
    "                FROM\n",
    "                    sequencedRun\n",
    "                WHERE \n",
    "                    direction != 0 AND\n",
    "                    passengerId == s.passengerId\n",
    "                GROUP BY\n",
    "                    passengerId\n",
    "                Having count(DISTINCT direction) == 2\n",
    "            )\n",
    "        ORDER BY \n",
    "            passengerId, seq\n",
    "    )\n",
    "    \n",
    "\n",
    "SELECT \n",
    "    passengerId,\n",
    "    max(countries) as longestRun\n",
    "FROM closedRun\n",
    "WHERE \n",
    "    countries IS NOT NULL\n",
    "GROUP BY \n",
    "    passengerId\n",
    "ORDER BY \n",
    "    passengerId\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|passengerId|longestRun|\n",
      "+-----------+----------+\n",
      "|         22|         4|\n",
      "|         53|         4|\n",
      "|        167|         2|\n",
      "|        204|         3|\n",
      "|        227|         1|\n",
      "+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Run longest closed run. took 5827 ms.\n",
      "\n",
      "(12) MapPartitionsRDD[78] at rdd at <console>:59 []\n",
      " |   MapPartitionsRDD[77] at rdd at <console>:59 []\n",
      " |   MapPartitionsRDD[76] at rdd at <console>:59 []\n",
      " |   ShuffledRowRDD[75] at rdd at <console>:59 []\n",
      " +-(12) MapPartitionsRDD[74] at rdd at <console>:59 []\n",
      "    |   MapPartitionsRDD[70] at rdd at <console>:59 []\n",
      "    |   MapPartitionsRDD[69] at rdd at <console>:59 []\n",
      "    |   ShuffledRowRDD[68] at rdd at <console>:59 []\n",
      "    +-(12) MapPartitionsRDD[67] at rdd at <console>:59 []\n",
      "       |   MapPartitionsRDD[66] at rdd at <console>:59 []\n",
      "       |   ShuffledRowRDD[65] at rdd at <console>:59 []\n",
      "       +-(1) MapPartitionsRDD[64] at rdd at <console>:59 []\n",
      "          |  MapPartitionsRDD[60] at rdd at <console>:59 []\n",
      "          |  FileScanRDD[59] at rdd at <console>:59 []\n",
      "(12) MapPartitionsRDD[134] at rdd at <console>:60 []\n",
      " |   MapPartitionsRDD[133] at rdd at <console>:60 []\n",
      " |   MapPartitionsRDD[132] at rdd at <console>:60 []\n",
      " |   ShuffledRowRDD[131] at rdd at <console>:60 []\n",
      " +-(12) MapPartitionsRDD[130] at rdd at <console>:60 []\n",
      "    |   MapPartitionsRDD[126] at rdd at <console>:60 []\n",
      "    |   ShuffledRowRDD[125] at rdd at <console>:60 []\n",
      "    +-(12) MapPartitionsRDD[124] at rdd at <console>:60 []\n",
      "       |   MapPartitionsRDD[123] at rdd at <console>:60 []\n",
      "       |   ShuffledRowRDD[122] at rdd at <console>:60 []\n",
      "       +-(12) MapPartitionsRDD[121] at rdd at <console>:60 []\n",
      "          |   MapPartitionsRDD[117] at rdd at <console>:60 []\n",
      "          |   MapPartitionsRDD[116] at rdd at <console>:60 []\n",
      "          |   MapPartitionsRDD[115] at rdd at <console>:60 []\n",
      "          |   ShuffledRowRDD[114] at rdd at <console>:60 []\n",
      "          +-(12) MapPartitionsRDD[113] at rdd at <console>:60 []\n",
      "             |   MapPartitionsRDD[112] at rdd at <console>:60 []\n",
      "             |   ShuffledRowRDD[111] at rdd at <console>:60 []\n",
      "             +-(12) MapPartitionsRDD[110] at rdd at <console>:60 []\n",
      "                |   MapPartitionsRDD[106] at rdd at <console>:60 []\n",
      "                |   MapPartitionsRDD[105] at rdd at <console>:60 []\n",
      "                |   MapPartitionsRDD[104] at rdd at <console>:60 []\n",
      "                |   ShuffledRowRDD[103] at rdd at <console>:60 []\n",
      "                +-(12) MapPartitionsRDD[102] at rdd at <console>:60 []\n",
      "                   |   MapPartitionsRDD[101] at rdd at <console>:60 []\n",
      "                   |   ShuffledRowRDD[100] at rdd at <console>:60 []\n",
      "                   +-(1) MapPartitionsRDD[99] at rdd at <console>:60 []\n",
      "                      |  MapPartitionsRDD[95] at rdd at <console>:60 []\n",
      "                      |  FileScanRDD[94] at rdd at <console>:60 []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "longestRun = [passengerId: int, longestRun: int]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, longestRun: int]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val longestRun = spark.sql(queryLongestRun)\n",
    "\n",
    "timed(\n",
    "    \"Run longest closed run.\",\n",
    "    longestRun.show(5)\n",
    ")\n",
    "println(timing)\n",
    "println(sequencedRun.rdd.toDebugString)\n",
    "println(longestRun.rdd.toDebugString)\n",
    "\n",
    "longestRun\n",
    "    .coalesce(1)\n",
    "    .write\n",
    "    .format(\"csv\")\n",
    "    .mode(SaveMode.Overwrite)\n",
    "    .option(\"header\", \"true\")\n",
    "    .save(RESULT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests\n",
    "TBD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
