{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 04\n",
    "Find the passengers who have been on more than N flights together within the range (from,to).\n",
    "\n",
    "## Assumptions\n",
    "1. Data is clearned and not errorneous\n",
    "2. Timezone consideration is not required\n",
    "\n",
    "## TODO\n",
    "Implement a matrix way. By creating M<sup>T</sup> * M, the diagonal represents the number of flghts of each passenger, and right top part represents how many flights (r/passenger 1, c/passenger2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.SaveMode\n",
    "import java.time.temporal.ChronoUnit\n",
    "import java.time.{Period, LocalDate, Instant}\n",
    "import java.sql.Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark parition control based on core availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NUM_CORES = 4\n",
       "NUM_PARTITIONS = 3\n",
       "spark = <lazy>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<lazy>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val NUM_CORES = 4\n",
    "val NUM_PARTITIONS = 3\n",
    "\n",
    "lazy val spark: SparkSession = SparkSession.builder()\n",
    "    .master(\"local\")\n",
    "    .appName(\"flight\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", NUM_CORES * NUM_PARTITIONS)\n",
    "spark.conf.set(\"spark.default.parallelism\", NUM_CORES * NUM_PARTITIONS)\n",
    "\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CSV_DELIMITER = ,\n",
       "FLIGHTDATA_CSV_PATH = ../resources/flightData.csv\n",
       "PASSENGER_CSV_PATH = ../resources/passengers.csv\n",
       "DATE_FORMAT = yyyy-MM-dd\n",
       "FLIGHT_DATE_FROM = 2017-01-01\n",
       "FLIGHT_DATE_TO = 2017-12-31\n",
       "NUM_FLIGHT_TOGETHER = 3\n",
       "RESULT_DIR = results/flightsTogether\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "results/flightsTogether"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val CSV_DELIMITER = \",\"\n",
    "val FLIGHTDATA_CSV_PATH = \"../resources/flightData.csv\"\n",
    "val PASSENGER_CSV_PATH = \"../resources/passengers.csv\"\n",
    "\n",
    "val DATE_FORMAT = \"yyyy-MM-dd\"\n",
    "val FLIGHT_DATE_FROM = \"2017-01-01\"\n",
    "val FLIGHT_DATE_TO   = \"2017-12-31\"\n",
    "val NUM_FLIGHT_TOGETHER = 3\n",
    "\n",
    "val RESULT_DIR = \"results/flightsTogether\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elapsed time profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timing = \n",
       "times = ListBuffer()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "clear: ()Unit\n",
       "average: ()Long\n",
       "timed: [T](label: String, code: => T)T\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ListBuffer()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.collection.mutable.ListBuffer\n",
    "\n",
    "val timing = new StringBuffer\n",
    "val times = new ListBuffer[Long]()\n",
    "\n",
    "def clear(): Unit = {\n",
    "    timing.setLength(0)\n",
    "    times.clear\n",
    "}\n",
    "def average(): Long = {\n",
    "    times.reduce(_+_) / times.length\n",
    "}\n",
    "\n",
    "/**\n",
    "@param label Description about the run\n",
    "@code code to execute\n",
    "@return execution\n",
    "*/\n",
    "def timed[T](label: String, code: => T): T = {\n",
    "    val start = System.currentTimeMillis()\n",
    "    val result = code\n",
    "    val stop = System.currentTimeMillis()\n",
    "    timing.append(s\"Processing $label took ${stop - start} ms.\\n\")\n",
    "    times.append(stop - start)\n",
    "    result\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<console>:45: error: missing argument list for method timed\n",
       "Unapplied methods are only converted to functions when a function type is expected.\n",
       "You can make this conversion explicit by writing `timed _` or `timed(_,_)` instead of `timed`.\n",
       "       timed\n",
       "       ^\n",
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// To flush out error: missing argument list for method timed\n",
    "println(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "save: (df: org.apache.spark.sql.DataFrame)Unit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save(df: DataFrame) = {\n",
    "    df.coalesce(1)\n",
    "    .write\n",
    "    .format(\"csv\")\n",
    "    .mode(SaveMode.Overwrite)\n",
    "    .option(\"header\", \"true\")\n",
    "    .save(RESULT_DIR)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark SQL runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run: (label: String, query: String, repeats: Int, toSave: Boolean)Long\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "/**\n",
    "Run the SparkSQL \n",
    "@param label Lable to describe this run\n",
    "@param query SQL \n",
    "@param repeats Number of run\n",
    "@return Average execution time in msec\n",
    "*/\n",
    "def run(label: String, query: String, repeats: Int, toSave: Boolean = false): Long = {\n",
    "    val result = spark.sql(query)\n",
    "\n",
    "    clear()\n",
    "    for (i <- (0 until repeats)){\n",
    "        timed(\n",
    "            label,\n",
    "            result.show(5)\n",
    "        )\n",
    "        println(timing)\n",
    "        println(s\"Average time $average ms\")\n",
    "    }\n",
    "    println(result.rdd.toDebugString)    \n",
    "\n",
    "    if(toSave) save(result)\n",
    "    average\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flightData = [passengerId: int, flightId: int ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, flightId: int ... 1 more field]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Transformations, no action yet\n",
    "val flightData = spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"delimiter\", \",\")\n",
    "    .option(\"dateFormat\", \"yyyy-MM-dd\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(\"../resources/flightData.csv\")\n",
    "    .select(\n",
    "        \"passengerId\",\n",
    "        \"flightId\",\n",
    "        \"date\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|count(DISTINCT date)|\n",
      "+--------------------+\n",
      "|                 342|\n",
      "+--------------------+\n",
      "\n",
      "+-------------------+\n",
      "|          min(date)|\n",
      "+-------------------+\n",
      "|2017-01-01 00:00:00|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+\n",
      "|          max(date)|\n",
      "+-------------------+\n",
      "|2017-12-31 00:00:00|\n",
      "+-------------------+\n",
      "\n",
      "+---------------------------+\n",
      "|count(DISTINCT passengerId)|\n",
      "+---------------------------+\n",
      "|                      15500|\n",
      "+---------------------------+\n",
      "\n",
      "+----------------+\n",
      "|min(passengerId)|\n",
      "+----------------+\n",
      "|               1|\n",
      "+----------------+\n",
      "\n",
      "+----------------+\n",
      "|max(passengerId)|\n",
      "+----------------+\n",
      "|           15500|\n",
      "+----------------+\n",
      "\n",
      "+------------------------+\n",
      "|count(DISTINCT flightId)|\n",
      "+------------------------+\n",
      "|                    1000|\n",
      "+------------------------+\n",
      "\n",
      "+-------------+\n",
      "|min(flightId)|\n",
      "+-------------+\n",
      "|            0|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|max(flightId)|\n",
      "+-------------+\n",
      "|          999|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightData.select(countDistinct(\"date\")).show()\n",
    "flightData.select(min(\"date\")).show()\n",
    "flightData.select(max(\"date\")).show()\n",
    "\n",
    "flightData.select(countDistinct(\"passengerId\")).show()\n",
    "flightData.select(min(\"passengerId\")).show()\n",
    "flightData.select(max(\"passengerId\")).show()\n",
    "\n",
    "flightData.select(countDistinct(\"flightId\")).show()\n",
    "flightData.select(min(\"flightId\")).show()\n",
    "flightData.select(max(\"flightId\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "queryFlightsTogether = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\n",
       "SELECT\n",
       "    f.passengerId AS `Passenger 1 ID`,\n",
       "    s.passengerId AS `Passenger 2 ID`,\n",
       "    count(s.flightId) AS `Number of flights together`,\n",
       "    '2017-01-01' as From,\n",
       "    '2017-12-31' as To\n",
       "FROM\n",
       "    flightData f INNER JOIN flightData s\n",
       "    ON f.flightId == s.flightId\n",
       "WHERE\n",
       "    f.passengerId != s.passengerId\n",
       "    AND f.date >= to_timestamp('2017-01-01', 'yyyy-MM-dd')\n",
       "    AND f.date <= to_timestamp('2017-12-31',   'yyyy-MM-dd')\n",
       "    AND s.date >= to_timestamp('2017-01-01', 'yyyy-MM-dd')\n",
       "    AND s.date <= to_timestamp('2017-12-31',   'yyyy-MM-dd')\n",
       "GROUP BY\n",
       "    f.passengerId, s.passengerId\n",
       "HAVING\n",
       "    count(s.flightId) > 3\n",
       "ORDER BY\n",
       "    f.passengerId, s.passengerId\n",
       "\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val queryFlightsTogether = s\"\"\"\n",
    "SELECT \n",
    "    f.passengerId AS `Passenger 1 ID`, \n",
    "    s.passengerId AS `Passenger 2 ID`, \n",
    "    count(s.flightId) AS `Number of flights together`,\n",
    "    '$FLIGHT_DATE_FROM' as From,\n",
    "    '$FLIGHT_DATE_TO' as To\n",
    "FROM\n",
    "    flightData f INNER JOIN flightData s\n",
    "    ON f.flightId == s.flightId\n",
    "WHERE \n",
    "    f.passengerId != s.passengerId\n",
    "    AND f.date >= to_timestamp('$FLIGHT_DATE_FROM', '$DATE_FORMAT')\n",
    "    AND f.date <= to_timestamp('$FLIGHT_DATE_TO',   '$DATE_FORMAT')\n",
    "    AND s.date >= to_timestamp('$FLIGHT_DATE_FROM', '$DATE_FORMAT')\n",
    "    AND s.date <= to_timestamp('$FLIGHT_DATE_TO',   '$DATE_FORMAT')\n",
    "GROUP BY \n",
    "    f.passengerId, s.passengerId\n",
    "HAVING \n",
    "    count(s.flightId) > $NUM_FLIGHT_TOGETHER\n",
    "ORDER BY \n",
    "    f.passengerId, s.passengerId\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order by (passengerId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|             1|            37|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            38|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            76|                         4|2017-01-01|2017-12-31|\n",
      "|             1|           120|                         4|2017-01-01|2017-12-31|\n",
      "|             1|          1694|                         4|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (passengerId) took 4494 ms.\n",
      "\n",
      "Average time 4494 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|             1|            37|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            38|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            76|                         4|2017-01-01|2017-12-31|\n",
      "|             1|           120|                         4|2017-01-01|2017-12-31|\n",
      "|             1|          1694|                         4|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (passengerId) took 4494 ms.\n",
      "Processing Order by (passengerId) took 3373 ms.\n",
      "\n",
      "Average time 3933 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|             1|            37|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            38|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            76|                         4|2017-01-01|2017-12-31|\n",
      "|             1|           120|                         4|2017-01-01|2017-12-31|\n",
      "|             1|          1694|                         4|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (passengerId) took 4494 ms.\n",
      "Processing Order by (passengerId) took 3373 ms.\n",
      "Processing Order by (passengerId) took 3387 ms.\n",
      "\n",
      "Average time 3751 ms\n",
      "(12) MapPartitionsRDD[411] at rdd at <console>:68 []\n",
      " |   MapPartitionsRDD[410] at rdd at <console>:68 []\n",
      " |   MapPartitionsRDD[409] at rdd at <console>:68 []\n",
      " |   MapPartitionsRDD[408] at rdd at <console>:68 []\n",
      " |   MapPartitionsRDD[407] at rdd at <console>:68 []\n",
      " |   *(2) Sort [passengerId#10 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(passengerId#10 ASC NULLS FIRST, 12)\n",
      "   +- *(1) FileScan csv [passengerId#10,flightId#11,date#14] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/masa/home/repository/git/oonisim/spark-programs/Flight/src/main/reso..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<passengerId:int,flightId:int,date:timestamp>\n",
      " MapPartitionsRDD[367] at run at ThreadPoolExecutor.java:1149 []\n",
      " |       CachedPartitions: 12; MemorySize: 514.1 KB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B\n",
      " |   MapPartitionsRDD[366] at run at ThreadPoolExecutor.java:1149 []\n",
      " |   ShuffledRowRDD[365] at run at ThreadPoolExecutor.java:1149 []\n",
      " +-(1) MapPartitionsRDD[364] at run at ThreadPoolExecutor.java:1149 []\n",
      "    |  MapPartitionsRDD[360] at run at ThreadPoolExecutor.java:1149 []\n",
      "    |  FileScanRDD[359] at run at ThreadPoolExecutor.java:1149 []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df = [passengerId: int, flightId: int ... 1 more field]\n",
       "timeOrderPassenger = 3751\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, flightId: int ... 1 more field]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var df = flightData\n",
    "    .orderBy(\"passengerId\")\n",
    "    .persist\n",
    "\n",
    "df.createOrReplaceTempView(\"flightData\")\n",
    "val timeOrderPassenger = run(\n",
    "    \"Order by (passengerId)\",\n",
    "    queryFlightsTogether,\n",
    "    3,\n",
    "    true\n",
    ")\n",
    "spark.catalog.dropTempView(\"df\")\n",
    "\n",
    "df.unpersist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order by (flightId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|             1|            37|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            38|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            76|                         4|2017-01-01|2017-12-31|\n",
      "|             1|           120|                         4|2017-01-01|2017-12-31|\n",
      "|             1|          1694|                         4|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (flightId) took 7593 ms.\n",
      "\n",
      "Average time 7593 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|             1|            37|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            38|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            76|                         4|2017-01-01|2017-12-31|\n",
      "|             1|           120|                         4|2017-01-01|2017-12-31|\n",
      "|             1|          1694|                         4|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (flightId) took 7593 ms.\n",
      "Processing Order by (flightId) took 6259 ms.\n",
      "\n",
      "Average time 6926 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|             1|            37|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            38|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            76|                         4|2017-01-01|2017-12-31|\n",
      "|             1|           120|                         4|2017-01-01|2017-12-31|\n",
      "|             1|          1694|                         4|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (flightId) took 7593 ms.\n",
      "Processing Order by (flightId) took 6259 ms.\n",
      "Processing Order by (flightId) took 6118 ms.\n",
      "\n",
      "Average time 6656 ms\n",
      "(12) MapPartitionsRDD[216] at rdd at <console>:68 []\n",
      " |   MapPartitionsRDD[215] at rdd at <console>:68 []\n",
      " |   MapPartitionsRDD[214] at rdd at <console>:68 []\n",
      " |   ShuffledRowRDD[213] at rdd at <console>:68 []\n",
      " +-(12) MapPartitionsRDD[212] at rdd at <console>:68 []\n",
      "    |   MapPartitionsRDD[208] at rdd at <console>:68 []\n",
      "    |   ShuffledRowRDD[207] at rdd at <console>:68 []\n",
      "    +-(12) MapPartitionsRDD[206] at rdd at <console>:68 []\n",
      "       |   MapPartitionsRDD[205] at rdd at <console>:68 []\n",
      "       |   MapPartitionsRDD[204] at rdd at <console>:68 []\n",
      "       |   MapPartitionsRDD[203] at rdd at <console>:68 []\n",
      "       |   *(2) Sort [flightId#11 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(flightId#11 ASC NULLS FIRST, 12)\n",
      "   +- *(1) FileScan csv [passengerId#10,flightId#11,date#14] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/masa/home/repository/git/oonisim/spark-programs/Flight/src/main/reso..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<passengerId:int,flightId:int,date:timestamp>\n",
      " MapPartitionsRDD[154] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |       CachedPartitions: 12; MemorySize: 392.5 KB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B\n",
      "       |   MapPartitionsRDD[153] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |   ShuffledRowRDD[152] at run at ThreadPoolExecutor.java:1149 []\n",
      "       +-(1) MapPartitionsRDD[151] at run at ThreadPoolExecutor.java:1149 []\n",
      "          |  MapPartitionsRDD[147] at run at ThreadPoolExecutor.java:1149 []\n",
      "          |  FileScanRDD[146] at run at ThreadPoolExecutor.java:1149 []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df = [passengerId: int, flightId: int ... 1 more field]\n",
       "timeOrderFlight = 6656\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, flightId: int ... 1 more field]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var df = flightData\n",
    "    .orderBy(\"flightId\")\n",
    "    .persist\n",
    "\n",
    "df.createOrReplaceTempView(\"flightData\")\n",
    "val timeOrderFlight = run(\n",
    "    \"Order by (flightId)\",\n",
    "    queryFlightsTogether,\n",
    "    3\n",
    ")\n",
    "spark.catalog.dropTempView(\"df\")\n",
    "\n",
    "df.unpersist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order by (\"passengerId\", \"flightId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|             1|            37|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            38|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            76|                         4|2017-01-01|2017-12-31|\n",
      "|             1|           120|                         4|2017-01-01|2017-12-31|\n",
      "|             1|          1694|                         4|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (passengerId, flightId) took 6750 ms.\n",
      "\n",
      "Average time 6750 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|             1|            37|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            38|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            76|                         4|2017-01-01|2017-12-31|\n",
      "|             1|           120|                         4|2017-01-01|2017-12-31|\n",
      "|             1|          1694|                         4|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (passengerId, flightId) took 6750 ms.\n",
      "Processing Order by (passengerId, flightId) took 5220 ms.\n",
      "\n",
      "Average time 5985 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|             1|            37|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            38|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            76|                         4|2017-01-01|2017-12-31|\n",
      "|             1|           120|                         4|2017-01-01|2017-12-31|\n",
      "|             1|          1694|                         4|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (passengerId, flightId) took 6750 ms.\n",
      "Processing Order by (passengerId, flightId) took 5220 ms.\n",
      "Processing Order by (passengerId, flightId) took 5232 ms.\n",
      "\n",
      "Average time 5734 ms\n",
      "(12) MapPartitionsRDD[287] at rdd at <console>:68 []\n",
      " |   MapPartitionsRDD[286] at rdd at <console>:68 []\n",
      " |   MapPartitionsRDD[285] at rdd at <console>:68 []\n",
      " |   ShuffledRowRDD[284] at rdd at <console>:68 []\n",
      " +-(12) MapPartitionsRDD[283] at rdd at <console>:68 []\n",
      "    |   MapPartitionsRDD[279] at rdd at <console>:68 []\n",
      "    |   ShuffledRowRDD[278] at rdd at <console>:68 []\n",
      "    +-(12) MapPartitionsRDD[277] at rdd at <console>:68 []\n",
      "       |   MapPartitionsRDD[276] at rdd at <console>:68 []\n",
      "       |   MapPartitionsRDD[275] at rdd at <console>:68 []\n",
      "       |   MapPartitionsRDD[274] at rdd at <console>:68 []\n",
      "       |   *(2) Sort [passengerId#10 ASC NULLS FIRST, flightId#11 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(passengerId#10 ASC NULLS FIRST, flightId#11 ASC NULLS FIRST, 12)\n",
      "   +- *(1) FileScan csv [passengerId#10,flightId#11,date#14] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/masa/home/repository/git/oonisim/spark-programs/Flight/src/main/reso..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<passengerId:int,flightId:int,date:timestamp>\n",
      " MapPartitionsRDD[225] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |       CachedPartitions: 12; MemorySize: 513.8 KB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B\n",
      "       |   MapPartitionsRDD[224] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |   ShuffledRowRDD[223] at run at ThreadPoolExecutor.java:1149 []\n",
      "       +-(1) MapPartitionsRDD[222] at run at ThreadPoolExecutor.java:1149 []\n",
      "          |  MapPartitionsRDD[218] at run at ThreadPoolExecutor.java:1149 []\n",
      "          |  FileScanRDD[217] at run at ThreadPoolExecutor.java:1149 []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df = [passengerId: int, flightId: int ... 1 more field]\n",
       "timeOrderPassengerFlight = 5734\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, flightId: int ... 1 more field]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var df = flightData\n",
    "    .orderBy(\"passengerId\", \"flightId\")\n",
    "    .persist\n",
    "\n",
    "df.createOrReplaceTempView(\"flightData\")\n",
    "val timeOrderPassengerFlight= run(\n",
    "    \"Order by (passengerId, flightId)\",\n",
    "    queryFlightsTogether,\n",
    "    3\n",
    ")\n",
    "spark.catalog.dropTempView(\"df\")\n",
    "\n",
    "df.unpersist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order by (\"passengerId\", \"date\")¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|             1|            37|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            38|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            76|                         4|2017-01-01|2017-12-31|\n",
      "|             1|           120|                         4|2017-01-01|2017-12-31|\n",
      "|             1|          1694|                         4|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (passengerId, date) took 6491 ms.\n",
      "\n",
      "Average time 6491 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|             1|            37|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            38|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            76|                         4|2017-01-01|2017-12-31|\n",
      "|             1|           120|                         4|2017-01-01|2017-12-31|\n",
      "|             1|          1694|                         4|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (passengerId, date) took 6491 ms.\n",
      "Processing Order by (passengerId, date) took 5979 ms.\n",
      "\n",
      "Average time 6235 ms\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|      From|        To|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "|             1|            37|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            38|                         4|2017-01-01|2017-12-31|\n",
      "|             1|            76|                         4|2017-01-01|2017-12-31|\n",
      "|             1|           120|                         4|2017-01-01|2017-12-31|\n",
      "|             1|          1694|                         4|2017-01-01|2017-12-31|\n",
      "+--------------+--------------+--------------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing Order by (passengerId, date) took 6491 ms.\n",
      "Processing Order by (passengerId, date) took 5979 ms.\n",
      "Processing Order by (passengerId, date) took 6217 ms.\n",
      "\n",
      "Average time 6229 ms\n",
      "(12) MapPartitionsRDD[358] at rdd at <console>:68 []\n",
      " |   MapPartitionsRDD[357] at rdd at <console>:68 []\n",
      " |   MapPartitionsRDD[356] at rdd at <console>:68 []\n",
      " |   ShuffledRowRDD[355] at rdd at <console>:68 []\n",
      " +-(12) MapPartitionsRDD[354] at rdd at <console>:68 []\n",
      "    |   MapPartitionsRDD[350] at rdd at <console>:68 []\n",
      "    |   ShuffledRowRDD[349] at rdd at <console>:68 []\n",
      "    +-(12) MapPartitionsRDD[348] at rdd at <console>:68 []\n",
      "       |   MapPartitionsRDD[347] at rdd at <console>:68 []\n",
      "       |   MapPartitionsRDD[346] at rdd at <console>:68 []\n",
      "       |   MapPartitionsRDD[345] at rdd at <console>:68 []\n",
      "       |   *(2) Sort [passengerId#10 ASC NULLS FIRST, date#14 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(passengerId#10 ASC NULLS FIRST, date#14 ASC NULLS FIRST, 12)\n",
      "   +- *(1) FileScan csv [passengerId#10,flightId#11,date#14] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/masa/home/repository/git/oonisim/spark-programs/Flight/src/main/reso..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<passengerId:int,flightId:int,date:timestamp>\n",
      " MapPartitionsRDD[296] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |       CachedPartitions: 12; MemorySize: 513.8 KB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B\n",
      "       |   MapPartitionsRDD[295] at run at ThreadPoolExecutor.java:1149 []\n",
      "       |   ShuffledRowRDD[294] at run at ThreadPoolExecutor.java:1149 []\n",
      "       +-(1) MapPartitionsRDD[293] at run at ThreadPoolExecutor.java:1149 []\n",
      "          |  MapPartitionsRDD[289] at run at ThreadPoolExecutor.java:1149 []\n",
      "          |  FileScanRDD[288] at run at ThreadPoolExecutor.java:1149 []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df = [passengerId: int, flightId: int ... 1 more field]\n",
       "timeOrderPassengerDate = 6229\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[passengerId: int, flightId: int ... 1 more field]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var df = flightData\n",
    "    .orderBy(\"passengerId\", \"date\")\n",
    "    .persist\n",
    "\n",
    "df.createOrReplaceTempView(\"flightData\")\n",
    "val timeOrderPassengerDate = run(\n",
    "    \"Order by (passengerId, date)\",\n",
    "    queryFlightsTogether,\n",
    "    3\n",
    ")\n",
    "spark.catalog.dropTempView(\"df\")\n",
    "\n",
    "df.unpersist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elepased Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Order by:\n",
      "(passengerId)           is 4257 ms\n",
      "(flightId)              is 6656 ms\n",
      "(passengerId, date)     is 6229 ms\n",
      "(passengerId, flightId) is 5734 ms\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "report = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\n",
       "Order by:\n",
       "(passengerId)           is 4257 ms\n",
       "(flightId)              is 6656 ms\n",
       "(passengerId, date)     is 6229 ms\n",
       "(passengerId, flightId) is 5734 ms\n",
       "\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val report = s\"\"\"\n",
    "Order by:\n",
    "(passengerId)           is $timeOrderPassenger ms\n",
    "(flightId)              is $timeOrderFlight ms\n",
    "(passengerId, date)     is $timeOrderPassengerDate ms\n",
    "(passengerId, flightId) is $timeOrderPassengerFlight ms\n",
    "\"\"\"\n",
    "println(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
